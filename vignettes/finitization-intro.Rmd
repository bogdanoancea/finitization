---
title: "Introduction to finitization"
author: "Bogdan Oancea"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo   # <-- only here, nowhere else
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
bibliography: finitization.bib     # <-- point to your .bib
link-citations: true               # <-- optional (auto-links cites)
vignette: >
  %\VignetteIndexEntry{Introduction to finitization}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 4,
  cache = FALSE
)
try(knitr::knit_cache$clear(), silent = TRUE)
```

# Introduction

The **finitization** package provides tools for computing finitized
versions of several well-known members of the *power series family*
(PSDs), including the Poisson, binomial, negative binomial, and
logarithmic distributions. Finitization is a probabilistic method that
transforms a discrete distribution - one with infinite
support - into a new distribution with finite support of specified order
*n*. Unlike truncation, which conditions the original distribution,
finitization constructs a new distribution that (under parameter
restrictions) preserves the first *n* moments of the parent distribution
[@golnabi2009finitizing; @levy2012moment].

This vignette is organized into two main parts. First, we provide a
**theoretical review** of the finitization concept, describing the
underlying families of distributions, the main methods of finitization
(PSF and NTSF), and key results such as the maximum feasible parameter
space (MFPS). Second, we present a **tutorial** on using the package,
including installation, functions for computing finitized probability
mass functions, quantiles and generate random variates. 
This structure allows the reader to both
understand the mathematical background and apply the package effectively
in practice.

# Finitization of Power Series Family of Probability Distributions

## What is finitization?

This vignette offers a concise theoretical overview of finitization,
highlighting its central ideas and main applications. Readers interested
in the full mathematical development, comprehensive proofs, and extended
examples are encouraged to consult the core references in the literature
[@golnabi2009finitizing; @levy2012moment; @levy2019application;
@cochran2013matching; @kirtland2018application].

Finitization is a probabilistic method that transforms a discrete
distribution - a member of the power series family such as
Poisson, negative binomial, binomial, or logarithmic - into a new
distribution with finite support of a specified size. Unlike simple
truncation, which conditions the original distribution on a restricted
domain, finitization constructs an alternative distribution whose first
*n* moments coincide with those of the parent distribution (a property
known as *moment preservation*) [@levy2012moment;
@golnabi2009finitizing]. This makes finitization particularly attractive
when one wishes to model real-world situations where the assumption of
infinite support is unrealistic but maintaining the original
distribution’s moment structure is essential. By doing so, finitization
not only provides a mathematically principled way to approximate
infinite-support models but also enables more efficient random variate
generation in simulation studies [@levy2019application].

## Usage of finitized probability distributions

Finitized distributions are especially useful in contexts where the
phenomenon being modeled has a natural upper bound. Examples
include[@levy2012moment]:

-   **Airplane seating:**\
    Suppose an airplane has $n$ seats, all prepurchased. The number of
    passengers arriving at the gate cannot exceed $n$. A standard
    Poisson distribution allows for arbitrarily large counts, which is
    unrealistic. An order-$n$ finitized Poisson correctly restricts the
    support to $\{0,1,\dots,n\}$.

-   **Book publisher:**\
    Consider a publisher producing textbooks with roughly *n* words per
    page. Traditionally, the number of misprints per page is modeled as
    Poisson with a small mean. However, the number of errors cannot
    exceed the number of words per page. A finitized Poisson of order
    *n* better reflects this bounded nature.

In each case, the standard Poisson or other infinite-support
distributions would assign positive probability to impossible outcomes,
while a *finitized* counterpart avoids this problem without distorting
key moment properties.

Another area where finitization can be used is in **random variate generation**. 
Simulation methods such as *aliasing* (efficient for
discrete distributions with finite support) become applicable once the
distribution is finitized. This can substantially accelerate random
variate generation while preserving a close fit to the parent
distribution.

The critical distinction from truncation is that truncation conditions
on the event $X \leq n$, which alters all the moments in unpredictable
ways and can misrepresent the underlying process
[@golnabi2009finitizing]. Finitization, by contrast, produces a new
distribution defined on $\{0,1,\ldots,n\}$ that preserves the first *n*
moments of the original model. This moment-preserving property makes
finitization superior when both realistic bounded support and fidelity
to the original statistical structure are required
[@levy2019application].

It is important to distinguish finitization from truncation:

```{r, echo=FALSE, message=FALSE}
library(knitr)

comparison <- data.frame(
  Feature = c("Definition", "Support", "Moment preservation",
              "Statistical behavior", "Simulation efficiency"),
  Truncation = c("Condition on X  <=  n",
                 "{0,1,…,n}",
                 "No – all moments are altered",
                 "Distorted relative to parent distribution",
                 "No special advantage"),
  Finitization = c("Construct new distribution on {0,…,n}",
                   "{0,1,…,n}",
                   "Yes – first n moments preserved",
                   "Consistent with parent distribution",
                   "Enables fast aliasing method")
)

kable(comparison, format = "markdown", align = "l")
```

## Two Finitization Methods: PSF and NTSF

### Power Series Distributions (PSDs)

A random variable $X$ has a *power series distribution* (PSD) if its pmf
can be written $$
f(x\mid\theta)=\Pr(X=x\mid\theta)=\frac{a_x\,\theta^x}{\eta(\theta)},\quad x=0,1,\ldots,\ \theta>0,
\tag{1}
$$ with $a_x\ge 0$ and normalizing function
$\eta(\theta)=\sum_{x=0}^{\infty} a_x\,\theta^x$. Equivalently, $$
f(x\mid\theta)=a_x\,\theta^x\,\tau(\theta),\qquad \tau(\theta)=\eta(\theta)^{-1}.
\tag{2}
$$ We call $\eta(\theta)$ the PSD base function and say that $\eta(\theta)$ generates the PSD.
Canonical examples include the Poisson, binomial, negative binomial,
and logarithmic distributions [@golnabi2009finitizing]. For the Poisson distribution,
the PSD base function can be expressed as $\eta(\theta)=\exp(\theta)$.


If the parent PSD has infinite support, finitization creates a new
distribution supported only on  $\{0,1,\dots,n\}$. 
The **partial sum finitization (PSF)** of order $n$ is defined as

$$
f_n(x \mid \theta) \;=\; a_x \theta^x \, \tau_n(\theta,n,x), 
\quad x = 0, 1, \dots, n,
$$

where

$$
\tau_n(\theta, n, x) = \sum_{j=0}^{n-x} b_j \theta^j
$$

is the **partial sum** of the power series expansion of $\tau(\theta)$
up to the $(n-x)$-th term.

By construction,

$$
\sum_{x=0}^n f_n(x \mid \theta) = 1,
$$

so $f_n(x \mid \theta)$ is a valid probability mass function under mild
parameter restrictions (which ensure nonnegativity of the finitized
probabilities).

The unit sum for $f_n$ is stated by the following theorem:

*Theorem 1 (unit-sum)*

Let $\theta$ be such that $f_n(x\mid \theta)>0$ for all $x=0,\ldots,n$.
Then $\sum_{x=0}^n f_n(x\mid \theta)=1$.

*Sketch.* Write $\tau(\theta)=\sum_{x=0}^{\infty} b_x \theta^x$. Since
$\eta(\theta)\tau(\theta) = \sum_{x=0}^{\infty} c_x\theta^x \equiv 1$, equating coefficients yields $c_0=1$
and $c_k=0$ for $k\ge 1$, where $c_k=\sum_{j=0}^{k} a_j b_{k-j}$. Hence
$$
\sum_{x=0}^{n} f_n(x\mid \theta)
=\sum_{x=0}^{n} a_x \theta^x \sum_{j=0}^{n-x} b_j \theta^j
=\sum_{k=0}^{n} c_k \theta^k
= c_0 = 1.
$$

For details and the full proof see Golnabi, Levy, and Cochran (2009)
[@golnabi2009finitizing].

This means that with some restrictions on the parameter $\theta$ we can
ensure that $f_n(x\mid \theta)>0$ for all $x=0,\ldots,n$ and it sums to
1 which makes $f_n$ a pdf.


For a PSD random variable $X$ with pmf in (1)–(2), the **moment generating function** (mgf) is 
$$M_X(t)=\frac{\eta(\theta e^t)}{\eta(\theta)}=\eta(\theta e^t)\,\tau(\theta)=\frac{\tau(\theta)}{\tau(\theta e^t)}$$,  [@golnabi2009finitizing].

Expanding $\eta(\theta e^t)\tau(\theta)$ gives $$
m_X(t)=\sum_{k=0}^{\infty} \theta^k \sum_{x=0}^{k} a_x\, b_{k-x}\, e^{t x}.
$$ For the order-$n$ finitized variable $X^{*}$ (with pmf $f_n$ above),
the mgf can be written the partial sum $$
m_{X^{*}}(t)=\sum_{k=0}^{n} \theta^k \sum_{x=0}^{k} a_x\, b_{k-x}\, e^{t x},
$$ i.e., the first $n\!+\!1$ terms of $m_X(t)$ from which we can compute
the first $n$ moments of $X^{*}$. [@golnabi2009finitizing]. With the
exception of the Poisson case - where the finitization coincides with
the parent distribution up to the first $n$ moments - the finitization
obtained by the PSD (partial sum) method generally does **not** preserve
the first $n$ moments of other distributions. In contrast, the NTSF
(Negative Taylor Series Finitization) method which we will introduce in
the next section, guarantees that the first $n$ moments of the
finitized distribution match those of the parent distribution for all
members of the power series family.

Table 1 presents 4 distributions and their 2nd order finitized
distributions using the partial sum finitization method.

```{r, echo=FALSE, results="asis"}
library(knitr)

tab1 <- data.frame(
  Distribution = c(
    "Poisson ($\\theta$)",
    "Negative binomial (k=2, $\\theta$)",
    "Binomial (N=4, p), $\\theta$ = p/(1-p)",
    "Logarithmic ($\\theta$)"
  ),
  `Pdf` = c(
    "$f(x)=\\frac{\\theta^x e^{-\\theta}}{x!}$",
    "$f(x)=(x+1)\\theta^x(1-\\theta)^2$",
    "$f(x)=\\binom{4}{x}\\frac{\\theta^x}{(1+\\theta)^4}$",
    "$f(x)=\\frac{\\theta^x}{x+1}\\cdot\\frac{\\theta}{-\\ln(1-\\theta)}$"
  ),
  
  `Series for $\\tau(\\theta)$)` = c(
    "$e^{-\\theta}=1-\\theta+\\theta^2/2-\\theta^3/6+\\cdots$",
    "$1-2\\theta+\\theta^2$",
    "$1-4\\theta+10\\theta^2-20\\theta^3+35\\theta^4+\\cdots$",
    "$1-\\theta/2-\\theta^2/12-\\theta^3/24-19\\theta^4/720+\\cdots$"
  ),
  `Finitized pdf (order 2)` = c(
    "$f_2(0)=1-\\theta+\\theta^2/2$, $f_2(1)=\\theta(1-\\theta)$, $f_2(2)=\\theta^2/2$",
    "$f_2(0)=1-2\\theta+\\theta^2$, $f_2(1)=2\\theta(1-2\\theta)$, $f_2(2)=3\\theta^2$",
    "$f_2(0)=1-4\\theta+10\\theta^2$, $f_2(1)=4\\theta(1-4\\theta)$, $f_2(2)=6\\theta^2$",
    "$f_2(0)=1-\\theta/2-\\theta^2/12$, $f_2(1)=\\tfrac{\\theta}{2}(1-\\theta/2)$, $f_2(2)=\\theta^2/3$"
  ),
  `Parameter restriction` = c(
    "$0<\\theta=\\lambda\\le 1$",
    "$0<2\\theta=\\lambda\\le 1$",
    "$0<4\\theta=\\lambda\\le 1$",
    "$0<\\theta/2=\\lambda\\le 1/2$"
  ),
  stringsAsFactors = FALSE,
  check.names = FALSE   # <- keeps your LaTeX column names
)

kable(tab1, escape = FALSE,
      caption = "Table 1. Common PSDs and their finitized pdfs of order 2 (after Golnabi, Levy & Cochran, 2009).")
```

**Note:** The logarithmic distribution shown in Table 1 (see also
[@golnabi2009finitizing]) is a slightly modified version of the standard
logarithmic distribution: its support is shifted back to start at $x=0$,
whereas the standard log-series distribution has support $x=1,2,\ldots$.

### Finitization via the Negative Taylor Series Method (NTSF)

The **Negative Taylor Series Method** (NTSF) provides an alternative to
the partial sum finitization (PSF). Both aim to transform a distribution
from the **power series family** (PSD) into a finitized version with
finite support $\{0,1,\dots,n\}$.\
The difference is that the NTSF starts from a **Negative Taylor Series
Distribution (NTSD)** representation, which has advantageous
moment-preserving properties.

------------------------------------------------------------------------

#### From Taylor expansion to a discrete distribution

Let $\delta(x)$ be a smooth function (continuous at 0 and infinitely
differentiable on $(-c, c)$ for some $c > 0$). We call it the **base function**. 
For constants $a$ and $b$ such that $a+b \in (-c,c)$, we have the Taylor expansion

$$
\delta(a+b) = \delta(a) + \frac{\delta'(a)}{1!}b
+ \frac{\delta^{(2)}(a)}{2!}b^2
+ \cdots + \frac{\delta^{(k)}(a)}{k!}b^k + \cdots.
$$

Now set $a = -\lambda$ and $b = \lambda$, with $\lambda \ne 0$ a parameter for which 
$\delta^{(k)}(-\lambda) \geq 0$ for all $k$. We call this condition the non-negativity condition. Then,

$$
\delta(0) = \delta(-\lambda) 
+ \delta'(-\lambda)\lambda 
+ \frac{\delta^{(2)}(-\lambda)}{2!}\lambda^2 
+ \cdots
$$

Without a loss of generality we can assume $\delta_0=1$ or we can rescale the base function by dividing it by $\delta_0$. This gives a distribution with support over the nonnegative integers
and a pmf

$$
g(k) = \frac{\delta^{(k)}(-\lambda)}{k!}\,\lambda^k, \quad k = 0,1,2,\dots
$$
which satisfies $\sum_{k=0}^\infty g(k) = \delta(0) = 1$.\
The random variable $X$ with pmf $g(k)$ is called a **Negative Taylor
Series Distribution (NTSD)**.

Its **moment generating function (mgf)** is

$$
m_X(t) = \sum_{k=0}^\infty \frac{\delta^{(k)}(-\lambda)}{k!}\,(\lambda e^t)^k
= \delta\!\left(\lambda(e^t - 1)\right).
$$

------------------------------------------------------------------------

#### Finitizing the NTSD

To finitize, we truncate the Maclaurin expansion of the NTSD base function:

$$
\delta(x) = \sum_{k=0}^\infty d_k x^k, \quad d_k = \frac{\delta^{(k)}(0)}{k!}, \; d_k \geq 0.
$$

The **order** $n$ finitized base function is

$$
\delta_n(x) = \sum_{k=0}^n d_k x^k.
$$

Using this finitized base function, we define the **NTSF(n)
distribution**:

$$
g_n(k) = \frac{\delta_n^{(k)}(-\lambda)}{k!}\,\lambda^k, 
\quad k = 0,1,\dots,n.
$$

Here, $\delta_n^{(k)}(-\lambda)$ denotes the $k$-th derivative of
$\delta_n(x)$ evaluated at $-\lambda$. By construction,
$\sum_{k=0}^n g_n(k) = 1$, so $g_n$ is a valid pmf under suitable
parameter restrictions.

------------------------------------------------------------------------

#### Moment preservation property

The mgf of the NTSD is

$$
m_X(t) = \delta\!\left(\lambda(e^t - 1)\right)
= d_0 + d_1\lambda(e^t-1) + d_2[\lambda(e^t-1)]^2 + \cdots.
$$

The mgf of the finitized version is obtained by truncating after the
$n$-th term:

$$
m_{X^{(n)}}(t) = d_0 + d_1\lambda(e^t-1) + d_2[\lambda(e^t-1)]^2 + \cdots + d_n[\lambda(e^t-1)]^n.
$$

Thus, $m_{X^{(n)}}(t)$ matches the first $n$ terms of $m_X(t)$.\
By differentiation, it follows that **the first** $n$ moments of the
finitized distribution equal those of the parent distribution:

$$
E\!\left[(X^{(n)})^r\right] = E\!\left[X^r\right], \quad r=1,2,\dots,n.
$$

------------------------------------------------------------------------

#### Comparison with PSF

-   In **PSF**, finitization preserves moments only in special cases
    (notably the Poisson).\
-   In **NTSF**, the moment preservation result is **general**: for any
    PSD, the first $n$ moments of the NTSF(n) match those of the parent
    distribution.\
-   For the Poisson distribution, PSF and NTSF give the same finitized
    distribution.\
-   For other PSDs (e.g., negative binomial, logarithmic), the two
    methods differ.

This makes NTSF a powerful and general finitization approach with strong
theoretical guarantees.

Table 2 show the finitization of the same distributions as those
presented in Table 1 but this time using the NTFS method. One can easily
note that only the finitization of the Poisson distribution is the same.

```{r, echo=FALSE, results="asis"}
library(knitr)

tab2 <- data.frame(
  Distribution = c(
    "Poisson($\\lambda$)",
    "Negative binomial (k=2, q)",
    "Binomial (N=4, p)",
    "Logarithmic($\\theta$)"
  ),
  `mgf  ` = c(
    "$e^{\\lambda(e^t - 1)}$",
    "$\\left( \\tfrac{p}{1 - q e^t} \\right)^2$",
    "$\\left( \\tfrac{q + p e^t}{q} \\right)^4$",
    "$\\tfrac{\\ln(1 - \\theta e^t)}{\\ln(1 - \\theta)}$"
  ),
  `NTSD base function $\\delta$(x)` = c(
    "$e^x$",
    "$(1 - x/p)^{-2}$",
    "$(1 + x)^4$",
    "$\\tfrac{\\ln(1 - \\theta - x)}{\\ln(1 - \\theta)}$"
  ),
  `NTSF(2) base function $\\delta_2$(x)` = c(
    "$1 + x + \\tfrac{x^2}{2}$",
    "$1 + \\tfrac{2x}{p} + \\tfrac{3x^2}{p^2}$",
    "$1 + 4x + 6x^2$",
    "$1 + x\\left(\\tfrac{1}{\\theta} - \\tfrac{1}{\\ln(1-\\theta)}\\right) + x^2\\left( \\tfrac{1}{(1-\\theta)^2} - \\tfrac{1}{2\\theta} + \\tfrac{1}{2(\\ln(1-\\theta))^2} \\right)$"
  ),
  `Finitized pdf $f_2(x)$` = c(
    "$f_2(0)=1-\\lambda+\\tfrac{\\lambda^2}{2}$<br>$f_2(1)=\\lambda(1-\\lambda)$<br>$f_2(2)=\\tfrac{\\lambda^2}{2}$",
    "$f_2(0)=\\tfrac{1-4q+6q^2}{(1-q)^2}$<br>$f_2(1)=\\tfrac{2q(4q-1)}{(1-q)^2}$<br>$f_2(2)=\\tfrac{3q^2}{(1-q)^2}$",
    "$f_2(0)=1-4p+6p^2$<br>$f_2(1)=4p(1-3p)$<br>$f_2(2)=6p^2$",
    "$f_2(0)=\\tfrac{4-5\\theta+6\\theta^2}{2\\theta \\ln(1-\\theta)}$<br>$f_2(1)=\\tfrac{4\\theta-3\\theta^2}{2\\theta \\ln(1-\\theta)}$<br>$f_2(2)=\\tfrac{2-3\\theta+2\\theta^2}{2\\theta \\ln(1-\\theta)}$"
  ),
  `Parameter restriction` = c(
    "$0 < \\lambda \\leq 1$",
    "$0 < q \\leq 1/4$",
    "$0 < p \\leq 1/3$",
    "$0 < \\theta \\leq 0.440423$"
  ),
    stringsAsFactors = FALSE,
  check.names = FALSE   # <- keeps your LaTeX column names
)

kable(tab2, format = "markdown", align = "l", caption = "Table 2. Common PSDs and their finitized pdfs of order 2 using the NTFS method")
```

## Maximum Feasible Parameter Space (MFPS)

When constructing finitized distributions, not every parameter value
from the parent distribution leads to a valid probability distribution.
For a finitization of order $n$, the probabilities must remain
nonnegative and sum to one. This naturally restricts the parameter space
of the parent power series distribution (PSD). The largest subset of the
parameter space that yields a valid finitized distribution is called the
*Maximum Feasible Parameter Space* (MFPS) [@golnabi2009finitizing;
@levy2012moment; @levy2019application].

### Why MFPS is Necessary

Without enforcing MFPS constraints, the finitized pmf may assign
negative probabilities, violating the axioms of probability. For
example, while the classical Poisson distribution admits any
$\lambda > 0$, its finitized counterpart only produces a valid pmf when
$0 < \lambda \leq 1$, regardless of the finitization order
[@golnabi2009finitizing]. For other PSDs, the admissible range is more
complex and depends explicitly on the finitization order $n$.

### How to Compute MFPS

Formally, the MFPS of a finitized distribution of order $n$ is the
largest interval $(\theta_{\min}, \theta_{\max}]$ such that all
finitized probabilities are nonnegative and sum to one
[@levy2019application].

-   The **upper bound** $\theta_{\max}$ is obtained by solving\
    $$
    g_n(n-1 \mid \theta) = 0,
    $$\
    where $g_n$ is the finitized pmf. The largest positive root gives
    the admissible upper bound.

-   The **lower bound** $\theta_{\min}$ is determined by examining when
    finitized probabilities comming from the upper bound toward the lower edge of the support first
    reach zero. In many PSDs (Poisson, Binomial, Negative Binomial) this
    bound is simply 0, since probabilities remain valid for arbitrarily
    small positive parameters. For the logarithmic distribution,
    however, the lower bound can be strictly positive and depends on the
    finitization order (see [@levy2019application] for proofs and
    demonstrations).

### Properties of MFPS

-   **Feasibility guarantee:** MFPS ensures that the finitized
    distribution is a proper pmf (all probabilities are nonnegative,
    summing to 1).
-   **Order dependence:** For distributions such as the negative
    binomial or logarithmic, the MFPS upper bound decreases as the
    finitization order $n$ increases.
-   **Monotonicity:** For most PSDs, the MFPS shrinks as $n$ increases.
    The exception is the Poisson distribution, whose MFPS remains
    constant across all orders.
-   **Stability for Poisson:** The Poisson case is simple and stable,
    since the MFPS remains fixed at $[0,1]$.
-   **Impact on modeling:** When selecting finitization order $n$, one
    must ensure that the parameter values of interest lie within the
    MFPS.

### Example: Poisson and Logarithmic Distributions

-   **Poisson:** For all orders $n$, the MFPS is $\lambda \in (0,1]$.
    This restriction is often natural in applications: if the mean count
    exceeds 1, one can rescale to a smaller time unit (e.g., accidents
    per day instead of accidents per week) to satisfy the condition
    [@golnabi2009finitizing].\
-   **Logarithmic:** The MFPS depends on the finitization order. For
    instance, with order $n=4$, the admissible range for $\theta$ is
    approximately $(0.00012,\,0.2397)$, with the upper bound decreasing
    as $n$ increases [@levy2019application].

------------------------------------------------------------------------

In summary, MFPS is a central concept in finitization: it specifies the
parameter values for which finitized distributions are mathematically
valid. For rigorous proofs, derivations, and additional examples across
the PSD family, the reader is referred to [@golnabi2009finitizing],
[@levy2012moment], and [@levy2019application].

# Installing the `finitization` Package

The `finitization` package is available through the
`R-universe repository`, which provides precompiled binaries for all
major operating systems - Windows, Linux, and macOS (both x86_64 and
arm64 architectures).

To install the package, simply run:

```{r, eval=FALSE}
install.packages(
  "finitization",
  repos = c("https://bogdanoancea.r-universe.dev", "https://cloud.r-project.org")
)
```

After installation, the package can be loaded as usual:

```{r, message=FALSE}
library(finitization)
```

------------------------------------------------------------------------

## External Dependencies

The package relies on three external C++ libraries:

-   **CLN (Class Library for Numbers):** <https://www.ginac.de/CLN/>\
-   **GiNaC (GiNaC is Not a CAS):** <https://www.ginac.de/>\
-   **GMP (GNU Multiple Precision Arithmetic Library):**
    <https://gmplib.org/>

These libraries are required because finitization involves symbolic
series expansions and moment-preserving transformations that need
**arbitrary-precision arithmetic** (CLN, GMP) and **symbolic
computation** (GiNaC). Without them, the numerical accuracy and
algebraic manipulations required by finitization would not be feasible.

------------------------------------------------------------------------

## Installing from source. Platform Notes

### Linux (Debian/Ubuntu)

Install the required libraries from the system package manager:

```{bash, eval=FALSE}
sudo apt-get update
sudo apt-get install -y libgmp-dev libcln-dev libginac-dev pkg-config
```

### macOS (Homebrew)

```{bash, eval=FALSE}
brew install gmp cln ginac pkg-config
```

### Windows

When building from source with **RTools** and **MSYS2**, CLN and GiNaC
must be compiled manually from their official websites. 1. **Install
RTools45**\
Download and run the installer from\
<https://cran.r-project.org/bin/windows/Rtools/>

2.  **Open the “MSYS2 UCRT 64‑bit” shell** Supposing that RTools44 is
    installed in "C:/rtools45" then double click on
    "C:/rtools45/ucrt64.exe".

3.  **Fully update MSYS2, update the package database and install the
    toolchain + pkgconf**\

``` bash
    pacman -Syu        # if it asks to close/reopen, do it, then run again:
    pacman -Syu
    pacman -S --needed mingw-w64-ucrt-x86_64-toolchain mingw-w64-ucrt-x86_64-pkgconf
```

4.  **Install GMP**\

``` bash
   pacman -S --needed mingw-w64-ucrt-x86_64-gmp
```

5.  **Download, compile and install CLN and GiNaC**\
    CLN and GiNaC are not available via pacman; follow the instructions
    on their websites:

    -   **CLN (Class Library for Numbers):** <https://www.ginac.de/cln>\
    -   **GiNaC (GiNaC is Not a CAS):** <https://www.ginac.de>

    Example (adjust versions as needed):

    ``` bash
    # CLN
    pacman -S --needed wget
    wget https://www.ginac.de/CLN/cln-1.3.7.tar.bz2
    tar xf cln-1.3.7.tar.bz2
    cd cln-1.3.7
    ./configure --prefix=/ucrt64
    make
    make install
    cd ..

    # GiNaC
    wget https://www.ginac.de/ginac-1.8.9.tar.bz2
    tar xf ginac-1.8.9.tar.bz2
    cd ginac-1.8.9
    ./configure --prefix=/ucrt64
    make
    make install
    ```

6.  **Make sure R sees the compilers**\
    In your R session (or add to your `~/.Renviron`):

```{r, eval=FALSE}
   Sys.setenv(PATH = paste(
     "C:/rtools44/ucrt64/bin",
     Sys.getenv("PATH"),
     sep = ";"
   ))
```

------------------------------------------------------------------------

## Building from Source
Once the external libraries a reinstalled, the package
can be built from the GitHub development version:

```{bash, eval=FALSE}
git clone https://github.com/bogdanoancea/finitization.git
cd finitization
R CMD build .
R CMD INSTALL finitization_0.1.0.tar.gz
```

Or install directly from R using **devtools**:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("bogdanoancea/finitization")
```

## Hints for Successful Installation

-   The **pkg-config** utility must be present and available to the
    compiler.
-   Header files and libraries for CLN and GiNaC (e.g., under
    `/usr/include`, `/usr/lib`, or `/ucrt64/include`, `/ucrt64/lib`)
    must be accessible on the compiler’s search path.
-   On Windows, potential errors such as “missing header” or “unresolved
    symbol” typically indicate that the build process is not detecting
    the static libraries.
-   In general, manual configuration is required only on Windows, since
    macOS and Linux distributions handle dependencies through system
    package managers.

------------------------------------------------------------------------

In summary, the installation should work out of the box on all
platforms using `R-universe repository`. Manual configuration is required only when compiling from
source.

# Finitized Negative Binomial distribution

This section illustrates the finitization of the negative binomial (NB)
distribution and its implementation in the `finitization` package. The
finitized NB restricts the support of the classical NB distribution to
$\{0,1,\dots,n\}$ while preserving the first $n$ moments of the parent
distribution [@levy2012moment; @kirtland2018application]. This
construction is particularly relevant in applied contexts where
unbounded support is unrealistic, such as in epidemiological models of
infection counts, bounded population studies, or simulation experiments
requiring efficient random variate generation [@golnabi2009finitizing].

The finitized NB distribution is parameterized by three values:\
- **finitization order** $n$, which determines the finite support
$\{0,\dots,n\}$;\
- **success probability** $q$ per trial;\
- **number of failures until stopping** $k > 0$.

The subsections below present the main functions provided in the package
together with executable examples.

```{r}
library(finitization)

# Parameters used in the examples
n <- 5      # finitization order -> support {0, 1, ..., 5}
q <- 0.10   # success probability per trial (must lie within MFPS)
k <- 2      # number of failures until stopping
x <- 0:n
```

## PMF - `dnegbinom()`

The function `dnegbinom()` returns the probability mass function (PMF)
of the finitized negative binomial distribution. When the argument `val`
is set to `NULL`, the function produces the complete PMF over the finite
support $\{0,1,\dots,n\}$. Alternatively, specific probability values
can be obtained by supplying a vector of evaluation points through
`val`. For numerical stability and applications requiring likelihood
calculations, logarithmic probabilities can be returned by specifying
`log = TRUE`.

```{r}
# Full PMF table over 0:n
pmf_tbl <- dnegbinom(n, q, k)       # val = NULL -> full table
head(pmf_tbl)

# PMF at selected points
d_points <- dnegbinom(n, q, k, val = c(0, 3, 5))
d_points

# Log-PMF for numerical work
d_log <- dnegbinom(n, q, k, val = 0:3, log = TRUE)
d_log
```

## CDF - `pnegbinom()`

The function `pnegbinom()` evaluates the cumulative distribution
function (CDF) of the finitized negative binomial distribution. By
default, it returns lower-tail probabilities $\Pr(X \leq x)$ for values
in $\{0,1,\dots,n\}$. Setting `lower.tail = FALSE` instead yields
upper-tail probabilities $\Pr(X > x)$, while the option `log.p = TRUE`
returns logarithmic probabilities, which may be advantageous in cases of
very small tail probabilities.

```{r}
# Full CDF table over 0:n
cdf_tbl <- pnegbinom(n, q, k)
head(cdf_tbl)

# Lower-tail CDF at a few points
p_lo <- pnegbinom(n, q, k, val = c(2, 3, 5))
p_lo

# Upper-tail probabilities (P[X > x])
p_hi <- pnegbinom(n, q, k, val = c(2, 3, 5), lower.tail = FALSE)
p_hi
```

## Quantiles - `qnegbinom()`

The function `qnegbinom()` provides the quantile function (inverse CDF)
of the finitized negative binomial distribution. Given a probability
level $p$, it returns the smallest integer $x \in \{0,\dots,n\}$ such
that $\Pr(X \leq x) \geq p$. The arguments `lower.tail` and `log.p`
control whether probabilities are interpreted in the lower- or
upper-tail sense and whether they are supplied on the log scale,
respectively. 

```{r}
# Median and 90th percentile
q_med_90 <- qnegbinom(n, q, k, p = c(0.5, 0.9))
q_med_90

# Upper-tail quantile example
q_upper10 <- qnegbinom(n, q, k, p = 0.1, lower.tail = FALSE)
q_upper10
```

## Random variates generation - `rnegbinom()`

The function `rnegbinom()` generates random variates from the finitized
negative binomial distribution on the finite support $\{0,1,\dots,n\}$.
The argument `no` specifies the number of independent draws to produce.
This functionality is essential for Monte Carlo experiments and
simulation studies, where one may wish to examine the finite-sample
properties of estimators or to benchmark statistical procedures under
finitized models.

```{r}
set.seed(42)
no  <- 5e4
r   <- rnegbinom(n, q, k, no)

# Compare empirical frequencies with the theoretical PMF
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[0:5, ]
```

```{r}
# Quick visual check
plot(x, pmf_tbl$prob, type = "h", lwd = 2, xlab = "x", ylab = "Probability",
     main = "Finitized NB: PMF vs empirical frequencies")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n", legend = c("PMF", "Empirical"), pch = c(NA, 16), lty = c(1, NA))
```

## Maximum Feasible Parameter Space - `getNegativeBinomialMFPS()`

The function `getNegativeBinomialMFPS()` determines the boundaries of
the maximum feasible parameter space (MFPS) for the finitized negative
binomial distribution. The MFPS specifies the admissible range of
parameter values (in particular for $k$) that guarantee the resulting
probability mass function remains nonnegative and normalized to one.
Ensuring that the chosen parameters lie within the MFPS is therefore
essential for obtaining a valid probability distribution under
finitization.

```{r}
mfps <- getNegativeBinomialMFPS(n, k)
length(mfps); head(mfps)
```

## Closed-form display - `printFinitizedNegativeBinomialDensity()`

The function `printFinitizedNegativeBinomialDensity()` prints the
finitized negative binomial density in a symbolic, human-readable form.
Optionally, evaluation points may be supplied through the argument
`val`, and setting `latex = TRUE` produces an expression suitable for
inclusion in LaTeX documents. This functionality facilitates the
communication of finitization results in teaching materials,
presentations, and publications.

```{r}
printFinitizedNegativeBinomialDensity(n, k)
printFinitizedNegativeBinomialDensity(n, k, val = c(0, 1, 2))
printFinitizedNegativeBinomialDensity(n, k, latex = TRUE)
```

------------------------------------------------------------------------

## Validation and Diagnostics

To ensure the correctness of the finitized negative binomial
implementation, it is useful to carry out a series of diagnostic checks.
These include verification of the normalization of the probability mass
function (PMF), consistency between the cumulative distribution function
(CDF) and the cumulative sum of the PMF, monotonicity of the CDF, the
accuracy of the quantile function through inversion tests, and finally,
agreement between theoretical moments derived from the PMF and empirical
moments obtained from simulated random draws. The following code
illustrates these diagnostic procedures in practice providing
evidence that the finitized NB functions operate reliably and preserve
theoretical properties.

```{r}
# PMF/CDF from the finitized NB
pmf <- dnegbinom(n, q, k)                 
cdf <- pnegbinom(n, q, k)

# 1) Normalization of PMF
norm_err <- abs(sum(pmf$density) - 1)
norm_err

# 2) CDF consistency
cdf_from_pmf <- cumsum(pmf$density)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf$cdf))
cdf_diff_max

# 3) Monotonicity of the CDF
is_monotone <- all(diff(cdf$cdf) >= -1e-12)
is_monotone

# 4) Quantile inversion check
p_vec <- c(0.01, 0.10, 0.25, 0.5, 0.9, 0.99)
q_inv <- qnegbinom(n, q, k, p = p_vec)
check_q_ok <- mapply(function(p, qx) {
  lhs <- cdf$cdf[qx + 1L]                  
  rhs <- if (qx > 0) cdf$cdf[qx] else 0    
  (lhs + 1e-12 >= p) && (rhs + 1e-12 < p)
}, p_vec, q_inv)
cbind(p = p_vec, q = q_inv, ok = check_q_ok)

# 5) Simulation vs. PMF moments
set.seed(123)
no <- 1e5
r  <- rnegbinom(n, q, k, no)

mu_th  <- sum(x * pmf$prob)
var_th <- sum((x - mu_th)^2 * pmf$prob)

mu_emp  <- mean(r)
var_emp <- var(r)

cbind(theoretical = c(mean = mu_th, var = var_th),
      empirical    = c(mean = mu_emp, var = var_emp))

```

## Moment preservation for the finitized Negative Binomial

In the following, we compare the first `n` moments of the finitized
negative binomial distribution with those of its parent distribution.
The classical negative binomial distribution is obtained using the
`stats` package in R. Since the `finitization` package and the `stats`
implementation adopt different parameterizations, a conversion is
required to ensure comparability.

In the finitization framework, the parameter `q` represents the
probability of success per trial, and `k` denotes the number of failures
until stopping. In contrast, in `stats::dnbinom`, the parameterization
is defined in terms of the number of successes (`size = k`) and the
success probability (`prob`). To reconcile the two conventions, the
mapping

$$
\texttt{size} = k, \quad \texttt{prob} = 1 - q
$$

must be applied.

This alignment of parameter definitions allows for a consistent
evaluation of the moment-preserving property of finitization, as
illustrated in the accompanying code.

```{r}
library(finitization)

# Parameters
n <- 5              # finitization order -> claims: first n moments preserved
q <- 0.10           # success probability per trial (package convention)
k <- 2              # number of failures until stopping (package convention)
x <- 0:n            # finite support of the finitized NB

# Parent NB in 'stats' uses: size = k (successes), prob = 1 - q (success probability)
size_parent <- k
prob_parent <- 1 - q
```

Next, we compute the finitized `pmf` as a numeric vector of length `n+1`

```{r}
pmf_raw <- dnegbinom(n, q, k) 
pmf_vec <- pmf_raw$prob
stopifnot(length(pmf_vec) == length(x))
stopifnot(abs(sum(pmf_vec) - 1) < 1e-10)
```

Now, we compute the parent Negative Binomial `pmf` on a sufficiently long
grid (for accurate moments). For this we build a grid `{0, ... , M}` so
that the upper tail is negligible (here $<10^{-14}$).

```{r}
# Find M so that tail <= 1e-14
M <- 50L
repeat {
  tail <- 1 - stats::pnbinom(M, size = size_parent, prob = prob_parent)
  if (tail < 1e-14) break
  M <- M * 2L
  if (M > 1e6) stop("Grid grew too large while bounding the tail.")
}
grid <- 0:M
p_parent <- stats::dnbinom(grid, size = size_parent, prob = prob_parent)
stopifnot(abs(sum(p_parent) - 1) < 1e-10)
```

Now we can compute and compare the first `n` raw moments for both
distributions:

```{r}
# Helper: raw moments from a discrete pmf
raw_moment <- function(x, p, r) sum((x^r) * p)

# Finitized moments on 0:n
mom_fin <- sapply(1:n, function(r) raw_moment(x, pmf_vec, r))

# Parent moments on 0:M (practically exact with very small tail)
mom_par <- sapply(1:n, function(r) raw_moment(grid, p_parent, r))

mom_cmp <- data.frame(
  r = 1:n,
  finitized = mom_fin,
  parent    = mom_par,
  diff      = mom_fin - mom_par
)
mom_cmp
```

We also present the mean and variance-the first two raw
moments-explicitly. Closed-form expressions are available for the parent
negative binomial distribution, and these provide a useful benchmark
against which the finitized moments can be validated. In particular, for
parameters $k$ (number of failures until stopping) and $q$ (success
probability per trial), the parent distribution satisfies

$$
\mathbb{E}[X] = \frac{kq}{1-q}, \qquad
\mathrm{Var}(X) = \frac{kq}{(1-q)^2}.
$$

These closed-form expressions offer an efficient reference point for
validation: they allow one to verify the accuracy of finitized moments
without resorting to numerical summation over the entire distributional
support. This comparison highlights the moment-preserving property of
finitization while emphasizing its consistency with the theoretical
parent model.

```{r}
# Mean and variance separately (these are moments 1 and 2)
mean_fin <- mom_fin[1]
var_fin  <- raw_moment(x, pmf_vec, 2) - mean_fin^2

# Parent mean/var using both summation and closed forms for cross-check
mean_par_sum <- mom_par[1]
var_par_sum  <- (raw_moment(grid, p_parent, 2) - mean_par_sum^2)

# Closed-form moments for stats::NB(size=k, prob=1-q):
# E[X] = k*q/(1-q), Var[X] = k*q/(1-q)^2
mean_par_cf <- k * q / (1 - q)
var_par_cf  <- k * q / (1 - q)^2

data.frame(
  quantity  = c("mean", "variance"),
  finitized = c(mean_fin, var_fin),
  parent_sum= c(mean_par_sum, var_par_sum),
  parent_cf = c(mean_par_cf, var_par_cf),
  diff_fin_parent_cf = c(mean_fin - mean_par_cf, var_fin - var_par_cf)
)
```

# Finitized Binomial Distribution

The classical binomial distribution models the number of successes in
$N$ independent Bernoulli trials, each with success probability $p$. Its
support is finite, $\{0,1,\dots,N\}$. Finitization provides an
alternative construction: a finitized binomial distribution of order $n$
that preserves the first $n$ moments of the parent binomial distribution
while adjusting the probability mass function. [@levy2012moment]. This
construction ensures that the finitized model remains consistent with
the theoretical binomial moments up to order $n$, even though its
support is restricted to $\{0,1,\dots,n\}$.

The finitized binomial distribution in the `finitization` package is
parameterized by: 
- **finitization order** $n$, which sets the support $\{0,\dots,n\}$;\
- **success probability** $p$;\
- **number of trials** $N$.

The next subsections present the available functions and illustrate
their use.

```{r}
library(finitization)

# Parameters for the examples
n <- 5      # finitization order -> support {0, 1, ..., 5}
N <- 10     # number of Bernoulli trials in the parent distribution
p <- 0.14    # success probability
x <- 0:n
```

## PMF - `dbinom()`

The probability mass function of the finitized binomial
distribution is computed by dbinom(). When `val = NULL`, the function
returns the entire PMF over ({0,\dots,n}). Specific probabilities can be
extracted by supplying values in `val`. For likelihood calculations and
improved numerical stability, log-probabilities are returned with the
argument `log = TRUE`.

```{r}
# Full PMF over 0:n
pmf_tbl <- finitization::dbinom(n, p, N)
head(pmf_tbl)

# PMF at selected points
d_points <- finitization::dbinom(n, p, N, val = c(0, 2, 5))
d_points

# Log-PMF for selected values
d_log <- finitization::dbinom(n, p, N, val = 0:3, log = TRUE)
d_log
```

## CDF - `pbinom()`

The cumulative distribution function is available via `pbinom()`.
By default, it returns lower-tail probabilities $\Pr(X \le x)$. Setting
`lower.tail = FALSE` gives upper-tail probabilities $\Pr(X > x)$. The
option `log.p = TRUE` returns values on the logarithmic scale.

```{r}
# Full CDF table over 0:n
cdf_tbl <- finitization::pbinom(n, p, N)
head(cdf_tbl)

# Lower-tail probabilities at selected points
p_lo <- finitization::pbinom(n, p, N, val = c(2, 4, 5))
p_lo

# Upper-tail probabilities
p_hi <- finitization::pbinom(n, p, N, val = c(2, 4, 5), lower.tail = FALSE)
p_hi
```

## Quantiles - `qbinom()`

The function `qbinom()` computes quantiles of the finitized binomial
distribution. Given probability levels (`u`), it
returns the smallest integer $x \in {0,\dots,n}$ such that
$\Pr(X \le x) \ge u$. The arguments `lower.tail` and `log.p` allow
specification of upper-tail and log-scale probabilities.

```{r}
# Median and 90th percentile
q_med_90 <- finitization::qbinom(n, p, N, prob = c(0.5, 0.9))
q_med_90

# Upper-tail quantile
q_upper10 <- finitization::qbinom(n, p, N, prob = 0.1, lower.tail = FALSE)
q_upper10
```

## Random Variates Generation - `rbinom()`

Random variates from the finitized binomial distribution are generated
using `rbinom()`. The argument no specifies the number of independent
draws. This functionality is useful for simulation studies, where
empirical properties can be compared with theoretical moments.

```{r}
set.seed(123)
no <- 5e4
r <- finitization::rbinom(n, p, N, no)

# Compare empirical frequencies with the theoretical PMF
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[1:6, ]

# Visual comparison of theoretical and empirical frequencies
plot(x, pmf_tbl$prob, type = "h", lwd = 2,
     main = "Finitized Binomial: PMF vs empirical frequencies",
     xlab = "x", ylab = "Probability")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n",
       legend = c("PMF", "Empirical"),
       pch = c(NA, 16), lty = c(1, NA))

```

## Maximum Feasible Parameter Space - `getBinomialMFPS()`

The function `getBinomialMFPS()` determines the maximum feasible
parameter space for the finitized binomial distribution. The MFPS
specifies the admissible range of parameters that guarantee the
distribution is valid (nonnegative probabilities and total probability
equal to one).

```{r}
mfps <- finitization::getBinomialMFPS(n, N)
mfps
```

## Closed-form display - `printFinitizedBinomialDensity()`

The density of the finitized binomial distribution can be displayed
symbolically with `printFinitizedBinomialDensity()`. This allows for
inspection of the closed-form representation of the probability
function. The option `latex = TRUE` produces output suitable for
inclusion in LaTeX documents.

```{r}
printFinitizedBinomialDensity(n, N)
printFinitizedBinomialDensity(n, N, val = c(0, 1, 2))
printFinitizedBinomialDensity(n, N, latex = TRUE)
```

## Validation and Diagnostics

Validation confirms that the finitized binomial functions operate
correctly. Checks include: normalization of the PMF, consistency between
CDF and PMF, monotonicity of the CDF, quantile inversion accuracy,
agreement between theoretical and empirical moments.

```{r}
pmf <- finitization::dbinom(n, p, N)
cdf <- finitization::pbinom(n, p, N)

# 1) Normalization
norm_err <- abs(sum(pmf$prob) - 1)

# 2) CDF consistency
cdf_from_pmf <- cumsum(pmf$prob)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf$cdf))

# 3) Monotonicity
is_monotone <- all(diff(cdf$cdf) >= -1e-12)

# 4) Quantile inversion check
p_vec <- c(0.1, 0.25, 0.5, 0.9)
q_inv <- finitization::qbinom(n, p, N, prob = p_vec)
check_q_ok <- mapply(function(u, qx) {
  lhs <- cdf$cdf[qx + 1L]
  rhs <- if (qx > 0) cdf$cdf[qx] else 0
  (lhs + 1e-12 >= u) && (rhs + 1e-12 < u)
}, p_vec, q_inv)

# 5) Simulation vs. PMF moments
set.seed(456)
r_samp <- finitization::rbinom(n, p, N, 1e5)
mu_emp <- mean(r_samp)
var_emp <- var(r_samp)

mu_th <- sum(x * pmf$prob)
var_th <- sum((x - mu_th)^2 * pmf$prob)

list(norm_err = norm_err,
     cdf_diff_max = cdf_diff_max,
     monotone = is_monotone,
     quantile_check = check_q_ok,
     mean_theoretical = mu_th, mean_empirical = mu_emp,
     var_theoretical = var_th, var_empirical = var_emp)
```

# Finitized Poisson Distribution

This section follows the structure introduced for the finitized
**Negative Binomial** and **Binomial** distributions, but in a more
concise form. The finitized Poisson of order $n$ replaces the
infinite-support Poisson by a distribution supported on $\{0,1,...,n\}$
that preserves the first $n$ moments of the parent model.

```{r}
library(finitization)

# Parameters used in the examples
n     <- 5      # finitization order -> support {0, 1, ..., 5}
theta <- 0.7    # Poisson mean (ensure theta lies within the MFPS for this n)
x     <- 0:n
```

## PMF - `dpois()`

Returns the finitized Poisson probability mass function. With
`val = NULL`, the full PMF over ({0,...,n}) is provided; logarithms are
available via `log = TRUE`.

```{r}
# Full PMF table over 0:n
pmf_tbl <- finitization::dpois(n, theta)
head(pmf_tbl)

# PMF at selected points
d_points <- finitization::dpois(n, theta, val = c(0, 2, 5))
d_points

# Log-PMF for numerical work
d_log <- finitization::dpois(n, theta, val = 0:3, log = TRUE)
d_log
```

## CDF - `ppois()`

Evaluates the finitized Poisson CDF. Lower tail $\Pr(X \le x)$ is
returned by default; set `lower.tail = FALSE` for $\Pr(X > x)$, and
`log.p = TRUE` for log-CDF.

```{r}
# Full CDF table
cdf_tbl <- ppois(n, theta)
head(cdf_tbl)

# Selected points (lower and upper tails)
p_lo <- ppois(n, theta, val = c(1, 3, 5))
p_hi <- ppois(n, theta, val = c(1, 3, 5), lower.tail = FALSE)
p_lo; p_hi
```

## Quantiles - `qpois()`

Inverts the finitized CDF. For a probability vector $p$, returns the
smallest $x \in {0,\dots,n}$ with $\Pr(X \le x) \ge p$.

```{r}
# Median and 90th percentile
q_med_90 <- qpois(n, theta, p = c(0.5, 0.9))
q_med_90

# Upper-tail quantile example
q_upper10 <- qpois(n, theta, p = 0.1, lower.tail = FALSE)
q_upper10
```

## Random Variates Generation - `rpois()`

```{r}
set.seed(2025)
no <- 5e4
r  <- rpois(n, theta, no)

# Empirical vs. theoretical frequencies (first rows)
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[1:6, ]
# Quick visual check
plot(x, pmf_tbl$prob, type = "h", lwd = 2,
     main = "Finitized Poisson: PMF vs empirical frequencies",
     xlab = "x", ylab = "Probability")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n",
       legend = c("PMF", "Empirical"),
       pch = c(NA, 16), lty = c(1, NA))
```

## Maximum Feasible Parameter Space - `getPoissonMFPS()`

Returns the MFPS for $\\theta$ given $n$; choosing $\\theta$ within
these bounds ensures a valid (nonnegative, normalized) finitized PMF.

```{r}
getPoissonMFPS(n)
```

## Closed-form - `printFinitizedPoissonDensity()`

Prints a symbolic representation of the finitized Poisson PMF;
`latex = TRUE` produces LaTeX-ready output.

```{r}
printFinitizedPoissonDensity(n)
printFinitizedPoissonDensity(n, val = c(0, 1, 2))
printFinitizedPoissonDensity(n, latex = TRUE)
```

## Validation and Disgnostics

The following diagnostics assess the internal consistency of the
finitized Poisson implementation: (i) normalization of the PMF; (ii)
agreement between the CDF and cumulative PMF; (iii) CDF monotonicity;
(iv) quantile inversion accuracy; (v) **moment preservation** (first `n`
raw moments) relative to the classical Poisson; and (vi) simulation
consistency.

```{r}
# Assumes 'n', 'theta', and x <- 0:n are already defined (see the Poisson section header).
# If not, uncomment the next three lines:
# n     <- 5
# theta <- 0.7
# x     <- 0:n

# --- 1) Finitized PMF/CDF ---
pmf_fin <- dpois(n, theta)    # data.frame: columns 'val', 'prob' (or log-prob if log=TRUE)
cdf_fin <- ppois(n, theta)    # data.frame: columns 'val', 'cdf'  (or log-cdf if log.p=TRUE)

# Normalization (PMF sums to 1 up to rounding)
norm_err <- abs(sum(pmf_fin$prob) - 1)

# CDF = cumulative sum of PMF (within numerical tolerance)
cdf_from_pmf <- cumsum(pmf_fin$prob)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf_fin$cdf))

# CDF monotonicity
is_monotone <- all(diff(cdf_fin$cdf) >= -1e-12)

list(
  normalization_error = norm_err,
  cdf_max_abs_diff    = cdf_diff_max,
  cdf_monotone        = is_monotone
)

# --- 2) Quantile inversion accuracy ---
# For each p, q := qpois(n, theta, p) should satisfy: F(q) >= p and F(q-1) < p
p_vec <- c(0.01, 0.10, 0.25, 0.5, 0.9, 0.99)
q_inv <- qpois(n, theta, p = p_vec)

# Helper to get F(x) from the finitized CDF table (values start at 0, so index = x+1)
Ffin <- function(qx) if (qx < 0) 0 else cdf_fin$cdf[qx + 1L]

qinversion_ok <- mapply(function(p, qx) {
  (Ffin(qx) + 1e-12 >= p) && (Ffin(qx - 1L) + 1e-12 < p)
}, p_vec, q_inv)

data.frame(p = p_vec, q = q_inv, inversion_ok = qinversion_ok)

# --- 3) Moment preservation vs. classical Poisson ---
# We compare the first n raw moments of the finitized Poisson to the parent Poisson($\\theta$).
# Parent moments are computed by summation over {0,...,M} with negligible tail (< 1e-14).

# Finitized raw moments on {0..n}
raw_moment <- function(xx, pp, r) sum((xx^r) * pp)
mom_fin <- sapply(1:n, function(r) raw_moment(x, pmf_fin$prob, r))

# Choose M so that tail <= 1e-14 for the classical Poisson
M <- max(50L, ceiling(theta + 10*sqrt(theta))) # start with a reasonable guess
repeat {
  tail <- 1 - stats::ppois(M, lambda = theta)  # NOTE: explicit 'stats::' to avoid masking
  if (tail < 1e-14) break
  M <- M * 2L
  if (M > 1e6) stop("Grid grew too large while bounding the tail.")
}
grid <- 0:M
p_parent <- stats::dpois(grid, lambda = theta)  # classical Poisson PMF on {0..M}

# Parent raw moments (virtually exact with tiny tail)
mom_par <- sapply(1:n, function(r) raw_moment(grid, p_parent, r))

mom_cmp <- data.frame(
  r         = 1:n,
  finitized = mom_fin,
  parent    = mom_par,
  diff      = mom_fin - mom_par
)
mom_cmp

# --- 4) Simulation sanity check ---
# Samples from finitized Poisson should exhibit moments close to the finitized-theoretical ones.
set.seed(2025)
no <- 1e5
rs <- rpois(n, theta, no)

mean_emp <- mean(rs)
var_emp  <- var(rs)

mean_fin <- sum(x * pmf_fin$prob)
var_fin  <- sum( (x - mean_fin)^2 * pmf_fin$prob )

data.frame(
  quantity   = c("mean", "variance"),
  empirical  = c(mean_emp, var_emp),
  finitized  = c(mean_fin, var_fin),
  abs_diff   = c(abs(mean_emp - mean_fin), abs(var_emp - var_fin))
)
```

# Finitized Logarithmic distribution

This section follows the structure already introduced for the finitized
**Negative Binomial**, **Binomial** and **Poisson** distributions, in a
concise form. The finitized logarithmic (log‑series) distribution of
order $n$ replaces the classical infinite‑support model with a
distribution supported on $\{0,1,...,n\}$ while preserving the first $n$
moments of its parent.

```{r}
library(finitization)

# Parameters used in the examples
n      <- 3      # finitization order -> support {0, 1, 2, 3}
theta  <- 0.16   # log-series parameter (0 < theta < 1); ensure within MFPS for 'n'
x      <- 0:n
```

------------------------------------------------------------------------

## PMF - `dlog()`

Returns the finitized logarithmic PMF. With `val = NULL`, the full PMF
over $\{0,...,n\}$ is returned; set `log = TRUE` for log‑probabilities.

```{r}
# Full PMF table over 0:n
pmf_tbl <- finitization::dlog(n, theta)
head(pmf_tbl)

# PMF at selected points
d_points <- finitization::dlog(n, theta, val = c(0, 2, 3))
d_points

# Log-PMF for numerical work
d_log <- finitization::dlog(n, theta, val = 0:3, log = TRUE)
d_log
```

------------------------------------------------------------------------

## CDF - `plog()`

Evaluates the finitized logarithmic CDF. Lower tail $\Pr(X \le x)$ is
returned by default; use `lower.tail = FALSE` for upper tails and
`log.p = TRUE` for log‑CDF.

```{r}
# Full CDF table
cdf_tbl <- finitization::plog(n, theta)
head(cdf_tbl)

# Selected points (lower and upper tails)
p_lo <- finitization::plog(n, theta, val = c(1, 3))
p_hi <- finitization::plog(n, theta, val = c(1, 3), lower.tail = FALSE)
p_lo; p_hi
```

------------------------------------------------------------------------

## Quantiles - `qlog()`

Inverts the finitized CDF. For a probability vector `p`, returns the
smallest $x \in \{0,...,n\}$ with $\Pr(X \le x) \ge p$.

```{r}
# Median and 90th percentile
q_med_90 <- finitization::qlog(n, theta, p = c(0.5, 0.9))
q_med_90

# Upper-tail quantile example
q_upper10 <- finitization::qlog(n, theta, p = 0.1, lower.tail = FALSE)
q_upper10
```

------------------------------------------------------------------------

## Random Variates Generation - `rlog()`

Generates samples from the finitized logarithmic distribution on
$\{0,...,n\}$.

```{r}
set.seed(2025)
no <- 5e6
r  <- finitization::rlog(n, theta, no)

# Empirical vs. theoretical frequencies (first rows)
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[1:4, ]
```

```{r}
# Quick visual check
plot(x, pmf_tbl$prob, type = "h", lwd = 2,
     main = "Finitized Logarithmic: PMF vs empirical frequencies",
     xlab = "x", ylab = "Probability")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n",
       legend = c("PMF", "Empirical"),
       pch = c(NA, 16), lty = c(1, NA))
```

------------------------------------------------------------------------

## Maximum Feasible Parameter Space - `getLogarithmicMFPS()`

Returns the **MFPS** for `theta` given `n`; parameter choices within
this interval ensure a valid finitized PMF (nonnegative and normalized).

```{r}
getLogarithmicMFPS(n)
```

------------------------------------------------------------------------

## Closed-form dispay - `printFinitizedLogarithmicDensity()`

Prints a symbolic representation of the finitized logarithmic PMF;
`latex = TRUE` yields LaTeX‑ready output.

```{r}
printFinitizedLogarithmicDensity(n, val = c(0))
```

------------------------------------------------------------------------

## Moment Preservation (first $n$ raw moments)

We compare the first $n$ raw moments of the finitized logarithmic
distribution with those of a **zero-including log-series parent** whose
moment generating function is $$m_X(t) \;=\; \frac{\ln(1-\theta e^{t})}{e^{t}\,\ln(1-\theta)}, \qquad 0<\theta<1$$. This corresponds to a log-series shifted to include 0 in its support,
with pmf $$
\Pr(X=x) \;=\; -\frac{1}{\ln(1-\theta)}\,\frac{\theta^{x+1}}{x+1}, \quad x=0,1,2,\dots
$$ We verify that the finitized distribution (order $n$, support
$\{0,\dots,n\}$) preserves the first $n$ raw moments of this parent.

```{r}
# --- Finitized raw moments on {0..n} ---
pmf_fin_tbl <- finitization::dlog(n, theta)   # expected: data.frame with columns 'val', 'prob'
stopifnot(is.data.frame(pmf_fin_tbl), all(c("val","prob") %in% names(pmf_fin_tbl)))
stopifnot(all(pmf_fin_tbl$val == x))
stopifnot(abs(sum(pmf_fin_tbl$prob) - 1) < 1e-12)

pmf_fin <- pmf_fin_tbl$prob
head(pmf_fin_tbl)


```

We compute parent moments by summation on ({0,...,M}) with negligible
tail (\< (10\^{-14})).

```{r}
# Parent pmf implied by the given MGF (zero-including log-series)
dlog_parent0 <- function(x, theta) {
  -1 / log(1 - theta) * theta^(x + 1) / (x + 1)
}

# Choose M until the remaining tail mass is < 1e-14
M <- 200L
repeat {
  s <- sum(dlog_parent0(0:M, theta))
  tail <- 1 - s
  if (tail < 1e-14) break
  M <- M * 2L
  if (M > 1e7) stop("Grid grew too large while bounding the tail.")
}
grid  <- 0:M
p_par <- dlog_parent0(grid, theta)
stopifnot(abs(sum(p_par) - 1) < 1e-10)

c(head(data.frame(x = grid, p = p_par), 6),
  tail_mass = 1 - sum(p_par))

raw_moment <- function(xx, pp, r) sum( (xx^r) * pp )

mom_fin <- sapply(1:n, function(r) raw_moment(x,    pmf_fin, r))
mom_par <- sapply(1:n, function(r) raw_moment(grid, p_par,    r))

mom_cmp <- data.frame(
  r         = 1:n,
  finitized = mom_fin,
  parent    = mom_par,
  diff      = mom_fin - mom_par
)
mom_cmp

```

------------------------------------------------------------------------

## Validation and Diagnostics

A compact set of checks, consistent with the other finitized families:

```{r}
pmf <- finitization::dlog(n, theta)
cdf <- finitization::plog(n, theta)

# Normalization
norm_err <- abs(sum(pmf$prob) - 1)

# CDF consistency and monotonicity
cdf_from_pmf <- cumsum(pmf$prob)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf$cdf))
is_monotone  <- all(diff(cdf$cdf) >= -1e-12)

# Quantile inversion check
p_vec <- c(0.01, 0.1, 0.25, 0.5, 0.9, 0.99)
q_inv <- finitization::qlog(n, theta, p = p_vec)
Ffin  <- function(qx) if (qx < 0) 0 else cdf$cdf[qx + 1L]
qinversion_ok <- mapply(function(p, qx) {
  (Ffin(qx) + 1e-12 >= p) && (Ffin(qx - 1L) + 1e-12 < p)
}, p_vec, q_inv)

list(
  normalization_error = norm_err,
  cdf_max_abs_diff    = cdf_diff_max,
  cdf_monotone        = is_monotone,
  quantile_inversion  = qinversion_ok
)
```

# Applications of finitized distributions

## Random Number Generators: Alias Method implemented in `finitization` vs. Parent Distributions

The `r*` functions in **finitization** implement an **aliasing**-based
generator to produce random variates on the finite support
$\{0,\dots,n\}$ with very low constant-time cost per draw. To illustrate
relative performance, we compare the finitized generators against their
classical/parent generators from `stats` package and, for the
logarithmic-series, from `extraDistr` package.

> **Note.** Parameters are chosen to lie within the **MFPS** for the
> finitized models so that the PMFs are valid (nonnegative and
> normalized).

```{r}
# ---- Timings for random variates  ----

# Workload
no      <- 1e6      # draws per generator call
batches <- 5L       # average over this many batches
target  <- 0.05     # >= 50 ms per batch for stable timing

# Optional parent for Logarithmic (extraDistr::rlgser)
have_extraDistr <- requireNamespace("extraDistr", quietly = TRUE)

# Auto-scale inner loop so each batch is long enough; return sec per one call
avg_time_per_call <- function(fun, b = batches, t = target) {
  reps <- 1L
  invisible(fun())  # warm-up
  repeat {
    t0 <- proc.time()[["elapsed"]]
    for (b in seq_len(b)) {
      for (r in seq_len(reps)) fun()
    }
    dt <- proc.time()[["elapsed"]] - t0
    if ((dt / b) >= t || reps >= 1e5L) {
      return((dt / b) / reps)
    }
    reps <- reps * 10L
  }
}

# Parameters
pars <- list(
  pois = list(n = 3L, theta = 0.10),
  nbin = list(n = 3L, q = 0.10, k = 5L),      # parent: size = k, prob = 1 - q
  bin  = list(n = 3L, p = 0.10, N = 10L),
  log  = list(n = 3L, theta = 0.10)           # parent via extraDistr::rlgser() - 1
)

# One-call closures (each call draws 'no' variates)
fun_fin_pois <- function() finitization::rpois(pars$pois$n, pars$pois$theta, no)
fun_par_pois <- function() stats::rpois(no, lambda = pars$pois$theta)

fun_fin_nbin <- function() finitization::rnegbinom(pars$nbin$n, pars$nbin$q, pars$nbin$k, no)
fun_par_nbin <- function() stats::rnbinom(no, size = pars$nbin$k, prob = 1 - pars$nbin$q)

fun_fin_bin  <- function() finitization::rbinom(pars$bin$n, pars$bin$p, pars$bin$N, no)
fun_par_bin  <- function() stats::rbinom(no, size = pars$bin$N, prob = pars$bin$p)

fun_fin_log  <- function() finitization::rlog(pars$log$n, pars$log$theta, no)
fun_par_log  <- if (have_extraDistr) function() extraDistr::rlgser(no, pars$log$theta) - 1L else NULL

# Measure (pass batches/target explicitly if you want)
t_fin_pois <- avg_time_per_call(fun_fin_pois, b = batches, t = target)
t_par_pois <- avg_time_per_call(fun_par_pois, b = batches, t = target)

t_fin_nbin <- avg_time_per_call(fun_fin_nbin, b = batches, t = target)
t_par_nbin <- avg_time_per_call(fun_par_nbin, b = batches, t = target)

t_fin_bin  <- avg_time_per_call(fun_fin_bin,  b = batches, t = target)
t_par_bin  <- avg_time_per_call(fun_par_bin,  b = batches, t = target)

t_fin_log  <- avg_time_per_call(fun_fin_log,  b = batches, t = target)
t_par_log  <- if (!is.null(fun_par_log)) avg_time_per_call(fun_par_log, b = batches, t = target) else NA_real_

# Speedup = parent / finitized (how many times faster finitized is)
res <- data.frame(
  Family  = c("Poisson", "NegBin", "Binomial", "Logarithmic"),
  Speedup = c(
    t_par_pois / t_fin_pois,
    t_par_nbin / t_fin_nbin,
    t_par_bin  / t_fin_bin,
    t_par_log  / t_fin_log
  ),
  check.names = FALSE
)

cat(
  sprintf("%-12s %s\n", "Family", "Speedup (finitized versus parent)"),
  paste(
    sprintf("%-12s %22.14f", res$Family, res$Speedup),
    collapse = "\n"
  ),
  sep = "\n"
)
```
## macOS–Specific Optimizations for Small Finitization Orders
The package places strong emphasis on achieving
platform-aware performance for random variate generation.
The default generator uses an optimized Vose–Walker alias table with a
16-way unrolled inner loop.  
This method performs extremely well on Linux/Windows but
on macOS, on both ARM64 and x86_64 architectures,the
situation is different.  
To address this drop in perfomance on macOS, 
\texttt{finitization} performs an automatic switch to a
small-support CDF ladder whenever the support size
\[
K = n + 1 \le K_{max}
\], wher $K_{max}$ is a constant. In the current implementation we used $K_{max} = 8$.
During \texttt{setProbs()}, the normalized PMF is cached for small \(K\);
\texttt{rvalues()} then builds a short CDF ladder and samples via a fully
unrolled sequence of comparisons:
\[
U < F(0) \Rightarrow 0,\quad
U < F(1) \Rightarrow 1,\quad
\ldots,\quad
\text{otherwise} \Rightarrow K-1.
\].
Sampling uses one uniform draw per variate and a fixed, short chain of
predictable branches, with no indirect jumps.

This solution yields substantial improvements for macOS
for finitization orders with \(K \le K_{max}\). In our benchmarks:

- Poisson: speedup \(\approx 1.87\times\)
- Negative binomial: speedup \(\approx 13.1\times\)
- Binomial: speedup \(\approx 3.84\times\)
- Logarithmic: speedup \(\approx 2.36\times\)

### Dispatch Logic

The choice between the alias generator and the small–\(K\) CDF ladder is
internal to the C++ backend and transparent to the user. Conceptually, the
logic is very simple:

- Let \(K = n + 1\) be the size of the finitized support \(\{0,\dots,n\}\).
- Detect whether the code is running on an macOS architecture.
- If \(\texttt{macOS} \,\land\, K \le K_{max}\), use a tiny-support CDF ladder
  (fully unrolled).
- Otherwise, use the Vose–Walker alias method with a 16-way unrolled loop.

This behavior can be summarized by the following pseudocode.

```text
function rvalues(no, n, theta):
    K <- n + 1

    if is_macOS() and K <= Kmax then
        # --- Small–K CDF ladder path ---
        # 1) Precompute CDF once from the finitized PMF:
        #    cdf[k] = sum_{j=0}^k p(j),  k = 0,...,K-1

        for i in 1..no:
            u <- Uniform(0, 1)

            if      u < cdf[0]           then x <- 0
            else if K > 1 and u < cdf[1] then x <- 1
            else if K > 2 and u < cdf[2] then x <- 2
            else                         x <- K - 1

            output x

    else
        # --- Alias method path (all x86_64 and ARM64 with K > 4) ---
        # alias tables prob[0..K-1], alias[0..K-1] are built in setProbs():
        # each draw uses one uniform and one unpredictable branch,
        # unrolled ×16 for throughput.

        for i in 1..no:
            uK <- Uniform(0, K)          # one uniform in [0, K)
            j  <- floor(uK)              # base column index
            f  <- uK - j                 # fractional part

            if f < prob[j] then
                x <- j                   # accept primary column
            else
                x <- alias[j]            # jump to alias column

            output x
```

# Session info

```{r session_info}
sessionInfo()
```

# References


