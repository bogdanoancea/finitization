---
title: "Introduction to finitization"
author: "Bogdan Oancea"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo   # <-- only here, nowhere else
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
bibliography: finitization.bib     # <-- point to your .bib
link-citations: true               # <-- optional (auto-links cites)
vignette: >
  %\VignetteIndexEntry{Introduction to finitization}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 4,
  cache = FALSE
)
try(knitr::knit_cache$clear(), silent = TRUE)
```
# Introduction


The **finitization** package provides tools for computing finitized versions of several well-known members of the *power series family* (PSDs), including the Poisson, binomial, negative binomial, and logarithmic distributions. Finitization is a probabilistic method that transforms a discrete distribution—often one with infinite support—into a new distribution with finite support of specified order *n*. Unlike truncation, which conditions the original distribution, finitization constructs a new distribution that (under parameter restrictions) preserves the first *n* moments of the parent distribution [@golnabi2009finitizing; @levy2012moment].  

This vignette is organized into two main parts. First, we provide a **theoretical review** of the finitization concept, describing the underlying families of distributions, the main methods of finitization (PSF and NTSF), and key results such as the maximum feasible parameter space (MFPS). Second, we present a **tutorial** on using the package, including installation, functions for computing finitized probability mass functions and random variates, and practical guidance for choosing the finitization order *n*. This structure allows the reader to both understand the mathematical background and apply the package effectively in practice.


# Finitization of Power Series Family of Probability Distributions

## What is finitization?

This vignette offers a concise theoretical overview of finitization, highlighting its central
ideas and main applications. Readers interested in the full mathematical development,
comprehensive proofs, and extended examples are encouraged to consult the core references in
the literature [@golnabi2009finitizing; @levy2012moment; @levy2019application;
@cochran2013matching; @kirtland2018application].

Finitization is a probabilistic method that transforms a discrete distribution—most often a member of the power series family such as Poisson, negative binomial, binomial, or logarithmic—into a new distribution with finite support of a specified size. Unlike simple truncation, which conditions the original distribution on a restricted domain, finitization constructs an alternative distribution whose first *n* moments coincide with those of the parent distribution (a property known as *moment preservation*) [@levy2012moment; @golnabi2009finitizing]. This makes finitization particularly attractive when one wishes to model real-world situations where the assumption of infinite support is unrealistic but maintaining the original distribution’s moment structure is essential. By doing so, finitization not only provides a mathematically principled way to approximate infinite-support models but also enables more efficient random variate generation in simulation studies [@levy2019application].


## Usage of finitized probability distributions
Finitized distributions are especially useful in contexts where the phenomenon being modeled has a natural upper bound. Examples include[@levy2012moment]:

- **Airplane seating:**  
  Suppose an airplane has \(n\) seats, all prepurchased. The number of passengers arriving at
  the gate cannot exceed \(n\). A standard Poisson distribution allows for arbitrarily large
  counts, which is unrealistic. An order-\(n\) finitized Poisson correctly restricts the support
  to \(\{0,1,\dots,n\}\).
  
- **Book publisher:**  
  Consider a publisher producing textbooks with roughly \(n\) words per page. Traditionally,
  the number of misprints per page is modeled as Poisson with a small mean. However, the
  number of errors cannot exceed the number of words per page. A finitized Poisson of order \(n\)
  better reflects this bounded nature.
  

In each case, the standard Poisson or other infinite-support distributions would assign positive probability to impossible outcomes, while a *finitized* counterpart avoids this problem without distorting key moment properties.


Another area where finitization can be used is in **random variate generation**. Simulation methods such as *aliasing* (efficient for discrete distributions with finite support) become applicable once the distribution is finitized. This can substantially accelerate random variate generation whil preserving a close fit to the parent distribution.
 

The critical distinction from truncation is that truncation conditions on the event \( X \leq n \), which alters all the moments in unpredictable ways and can misrepresent the underlying process [@golnabi2009finitizing]. Finitization, by contrast, produces a new distribution defined on \(\{0,1,\ldots,n\}\) that preserves the first *n* moments of the original model. This moment-preserving property makes finitization superior when both realistic bounded support and fidelity to the original statistical structure are required [@levy2019application].

It is important to distinguish finitization from truncation:

```{r, echo=FALSE, message=FALSE}
library(knitr)

comparison <- data.frame(
  Feature = c("Definition", "Support", "Moment preservation",
              "Statistical behavior", "Simulation efficiency", "Interpretation"),
  Truncation = c("Condition on X  <=  n",
                 "{0,1,…,n}",
                 "No – all moments are altered",
                 "Distorted relative to parent distribution",
                 "No special advantage",
                 "Reweighted version of parent distribution"),
  Finitization = c("Construct new distribution on {0,…,n}",
                   "{0,1,…,n}",
                   "Yes – first n moments preserved",
                   "Consistent with parent distribution",
                   "Enables fast aliasing method",
                   "Faithful bounded analog of parent distribution")
)

kable(comparison, format = "markdown", align = "l")
```

## Two Finitization Methods: PSF and NTSF

### Power Series Distributions (PSDs)

A random variable \(X\) has a *power series distribution* (PSD) if its pmf can be written
\[
f(x\mid\theta)=\Pr(X=x\mid\theta)=\frac{a_x\,\theta^x}{\eta(\theta)},\quad x=0,1,\ldots,\ \theta>0,
\tag{1}
\]
with \(a_x\ge 0\) and normalizing function \(\eta(\theta)=\sum_{x=0}^{\infty} a_x\,\theta^x\). Equivalently,
\[
f(x\mid\theta)=a_x\,\theta^x\,\tau(\theta),\qquad \tau(\theta)=\eta(\theta)^{-1}.
\tag{2}
\]
Canonical examples include the Poisson, binomial, negative binomial, and logarithmic distributions [@golnabi2009finitizing].

The unit sum for \(f_n\) is stated by the following theorem:

*Theorem 1 (unit-sum)*

Let \(\theta\) be such that \(f_n(x\mid \theta)>0\) for all \(x=0,\ldots,n\). Then \(\sum_{x=0}^n f_n(x\mid \theta)=1\).

*Sketch.* Write \(\tau(\theta)=\sum_{j=0}^{\infty} b_j \theta^j\). Since \(\eta(\theta)\tau(\theta)\equiv 1\), equating coefficients yields
\(c_0=1\) and \(c_k=0\) for \(k\ge 1\), where \(c_k=\sum_{j=0}^{k} a_j b_{k-j}\). Hence
\[
\sum_{x=0}^{n} f_n(x\mid \theta)
=\sum_{x=0}^{n} a_x \theta^x \sum_{j=0}^{n-x} b_j \theta^j
=\sum_{k=0}^{n} c_k \theta^k
= c_0 = 1.
\]

For details and the full proof see Golnabi, Levy, and Cochran (2009) [@golnabi2009finitizing].

This means that with some restrictions on the parameter \(\theta\) we can ensure that \(f_n(x\mid \theta)>0\) for all \(x=0,\ldots,n\) and it sums to 1 which makes \(f_n\) a pdf.

If the parent PSD has infinite support, finitization creates a new distribution supported only on  
\(\{0,1,\dots,n\}\). The **partial sum finitization (PSF)** of order \(n\) is defined as

\[
f_n(x \mid \theta) \;=\; a_x \theta^x \, \tau_n(\theta, x), 
\quad x = 0, 1, \dots, n,
\]

where  

\[
\tau_n(\theta, x) = \sum_{j=0}^{n-x} b_j \theta^j
\]

is the **partial sum** of the power series expansion of \(\tau(\theta)\) up to the \((n-x)\)-th term.  

By construction,

\[
\sum_{x=0}^n f_n(x \mid \theta) = 1,
\]

so \(f_n(x \mid \theta)\) is a valid probability mass function under mild parameter restrictions
(which ensure nonnegativity of the finitized probabilities).  


For a PSD random variable \(X\) with pmf in (1)–(2), the **moment generating function** (mgf)  is
\[
M_X(t)=\frac{\eta(\theta e^t)}{\eta(\theta)}=\eta(\theta e^t)\,\tau(\theta)=\frac{\tau(\theta)}{\tau(\theta e^t)},
\] [@golnabi2009finitizing].

Expanding \(\eta(\theta e^t)\tau(\theta)\) gives
\[
m_X(t)=\sum_{k=0}^{\infty} \theta^k \sum_{x=0}^{k} a_x\, b_{k-x}\, e^{t x}.
\]
For the order-\(n\) finitized variable \(X^{*}\) (with pmf \(f_n\) above), the mgf can be written the partial sum
\[
m_{X^{*}}(t)=\sum_{k=0}^{n} \theta^k \sum_{x=0}^{k} a_x\, b_{k-x}\, e^{t x},
\]
i.e., the first \(n\!+\!1\) terms of \(m_X(t)\) from which we can compute the first \(n\) moments of \(X^{*}\). [@golnabi2009finitizing]. 
With the exception of the Poisson case—where the finitization coincides with the parent
distribution up to the first \(n\) moments—the finitization obtained by the PSD (partial sum)
method generally does **not** preserve the first \(n\) moments of other distributions.
In contrast, the NTSF (Negative Taylor Series Finitization) method which we will introduce in the next sections, guarantees that the first \(n\) moments of the finitized distribution match those of the parent distribution for all members of the power series family.

Table 1 presents 4 distributions and their 2nd order finitized distributions using the partial sum finitization method.
```{r, echo=FALSE, results="asis"}
library(knitr)

tab1 <- data.frame(
  Distribution = c(
    "Poisson ($\\theta$)",
    "Negative binomial (k=2, $\\theta$)",
    "Binomial (N=4, p), $\\theta$ = p/(1-p)",
    "Logarithmic ($\\theta$)"
  ),
  `Pdf` = c(
    "$f(x)=\\frac{\\theta^x e^{-\\theta}}{x!}$",
    "$f(x)=(x+1)\\theta^x(1-\\theta)^2$",
    "$f(x)=\\binom{4}{x}\\frac{\\theta^x}{(1+\\theta)^4}$",
    "$f(x)=\\frac{\\theta^x}{x+1}\\cdot\\frac{\\theta}{-\\ln(1-\\theta)}$"
  ),
  
  `Series for $\\tau(\\theta)$)` = c(
    "$e^{-\\theta}=1-\\theta+\\theta^2/2-\\theta^3/6+\\cdots$",
    "$1-2\\theta+\\theta^2$",
    "$1-4\\theta+10\\theta^2-20\\theta^3+35\\theta^4+\\cdots$",
    "$1-\\theta/2-\\theta^2/12-\\theta^3/24-19\\theta^4/720+\\cdots$"
  ),
  `Finitized pdf (order 2)` = c(
    "$f_2(0)=1-\\theta+\\theta^2/2$, $f_2(1)=\\theta(1-\\theta)$, $f_2(2)=\\theta^2/2$",
    "$f_2(0)=1-2\\theta+\\theta^2$, $f_2(1)=2\\theta(1-2\\theta)$, $f_2(2)=3\\theta^2$",
    "$f_2(0)=1-4\\theta+10\\theta^2$, $f_2(1)=4\\theta(1-4\\theta)$, $f_2(2)=6\\theta^2$",
    "$f_2(0)=1-\\theta/2-\\theta^2/12$, $f_2(1)=\\tfrac{\\theta}{2}(1-\\theta/2)$, $f_2(2)=\\theta^2/3$"
  ),
  `Parameter restriction` = c(
    "$0<\\theta=\\lambda\\le 1$",
    "$0<2\\theta=\\lambda\\le 1$",
    "$0<4\\theta=\\lambda\\le 1$",
    "$0<\\theta/2=\\lambda\\le 1/2$"
  ),
  stringsAsFactors = FALSE,
  check.names = FALSE   # <- keeps your LaTeX column names
)

kable(tab1, escape = FALSE,
      caption = "Table 1. Common PSDs and their finitized pdfs of order 2 (after Golnabi, Levy & Cochran, 2009).")
```


**Note:** The logarithmic distribution shown in Table 1 (see also [@golnabi2009finitizing]) is a slightly modified version of the standard logarithmic distribution: its support is shifted back to start at \(x=0\), whereas the standard log-series distribution has support \(x=1,2,\ldots\). 


### Finitization via the Negative Taylor Series Method (NTSF)

The **Negative Taylor Series Method** (NTSF) provides an alternative to the partial sum
finitization (PSF). Both aim to transform a distribution from the **power series family** (PSD)
into a finitized version with finite support \(\{0,1,\dots,n\}\).  
The difference is that the NTSF starts from a **Negative Taylor Series Distribution (NTSD)**
representation, which has advantageous moment-preserving properties.

---

#### From Taylor expansion to a discrete distribution

Let \(\delta(x)\) be a smooth function (continuous at 0 and infinitely differentiable on
\((-c, c)\) for some \(c > 0\)). For constants \(a\) and \(b\) such that \(a+b \in (-c,c)\), we have
the Taylor expansion

\[
\delta(a+b) = \delta(a) + \frac{\delta'(a)}{1!}b
+ \frac{\delta^{(2)}(a)}{2!}b^2
+ \cdots + \frac{\delta^{(k)}(a)}{k!}b^k + \cdots.
\]

Now set \(a = -\lambda\) and \(b = \lambda\), with \(\lambda > 0\).
If \(\delta^{(k)}(-\lambda) \geq 0\) for all \(k\), t

\[
\delta(0) = \delta(-\lambda) 
+ \delta'(-\lambda)\lambda 
+ \frac{\delta^{(2)}(-\lambda)}{2!}\lambda^2 
+ \cdots
\]

which gives a distribution with support over the nonnegative integers and a pdf / pmf

\[
g(k) = \frac{\delta^{(k)}(-\lambda)}{k!}\,\lambda^k, \quad k = 0,1,2,\dots
\]

which satisfies \(\sum_{k=0}^\infty g(k) = \delta(0) = 1\).  
The random variable \(X\) with pmf \(g(k)\) is called a **Negative Taylor Series Distribution (NTSD)**.

Its **moment generating function (mgf)** is

\[
m_X(t) = \sum_{k=0}^\infty \frac{\delta^{(k)}(-\lambda)}{k!}\,(\lambda e^t)^k
= \delta\!\left(\lambda(e^t - 1)\right).
\]

---

#### Finitizing the NTSD

To finitize, truncate the Maclaurin expansion of the NTSD base function:

\[
\delta(x) = \sum_{k=0}^\infty d_k x^k, \quad d_k = \frac{\delta^{(k)}(0)}{k!}, \; d_k \geq 0.
\]

The **order \(n\) finitized base function** is

\[
\delta_n(x) = \sum_{k=0}^n d_k x^k.
\]

Using this finitized base function, we define the **NTSF(n) distribution**:

\[
g_n(k) = \frac{\delta_n^{(k)}(-\lambda)}{k!}\,\lambda^k, 
\quad k = 0,1,\dots,n.
\]

Here, \(\delta_n^{(k)}(-\lambda)\) denotes the \(k\)-th derivative of \(\delta_n(x)\) evaluated at \(-\lambda\).
By construction, \(\sum_{k=0}^n g_n(k) = 1\), so \(g_n\) is a valid pmf under suitable parameter
restrictions.

---

#### Moment preservation property

The mgf of the NTSD is

\[
m_X(t) = \delta\!\left(\lambda(e^t - 1)\right)
= d_0 + d_1\lambda(e^t-1) + d_2[\lambda(e^t-1)]^2 + \cdots.
\]

The mgf of the finitized version is obtained by truncating after the \(n\)-th term:

\[
m_{X^{(n)}}(t) = d_0 + d_1\lambda(e^t-1) + d_2[\lambda(e^t-1)]^2 + \cdots + d_n[\lambda(e^t-1)]^n.
\]

Thus, \(m_{X^{(n)}}(t)\) matches the first \(n\) terms of \(m_X(t)\).  
By differentiation, it follows that **the first \(n\) moments of the finitized distribution equal
those of the parent distribution**:

\[
E\!\left[(X^{(n)})^r\right] = E\!\left[X^r\right], \quad r=1,2,\dots,n.
\]

---

#### Comparison with PSF

- In **PSF**, finitization preserves moments only in special cases (notably the Poisson).  
- In **NTSF**, the moment preservation result is **general**: for any PSD, the first \(n\) moments
of the NTSF(n) match those of the parent distribution.  
- For the Poisson distribution, PSF and NTSF give the same finitized distribution.  
- For other PSDs (e.g., negative binomial, logarithmic), the two methods differ.


This makes NTSF a powerful and general finitization approach with strong theoretical guarantees.

Table 2 show the finitization of the same distributions as those presented in Table 1 but this time using the NTFS method. One can easily note that only the finitization of the Poisson distribution is the same.

```{r, echo=FALSE, results="asis"}
library(knitr)

tab2 <- data.frame(
  Distribution = c(
    "Poisson($\\lambda$)",
    "Negative binomial (k=2, q)",
    "Binomial (N=4, p)",
    "Logarithmic($\\theta$)"
  ),
  `mgf  ` = c(
    "$e^{\\lambda(e^t - 1)}$",
    "$\\left( \\tfrac{p}{1 - q e^t} \\right)^2$",
    "$\\left( \\tfrac{q + p e^t}{q} \\right)^4$",
    "$\\tfrac{\\ln(1 - \\theta e^t)}{\\ln(1 - \\theta)}$"
  ),
  `NTSD base function $\\delta$(x)` = c(
    "$e^x$",
    "$(1 - x/p)^{-2}$",
    "$(1 + x)^4$",
    "$\\tfrac{\\ln(1 - \\theta - x)}{\\ln(1 - \\theta)}$"
  ),
  `NTSF(2) base function $\\delta_2$(x)` = c(
    "$1 + x + \\tfrac{x^2}{2}$",
    "$1 + \\tfrac{2x}{p} + \\tfrac{3x^2}{p^2}$",
    "$1 + 4x + 6x^2$",
    "$1 + x\\left(\\tfrac{1}{\\theta} - \\tfrac{1}{\\ln(1-\\theta)}\\right) + x^2\\left( \\tfrac{1}{(1-\\theta)^2} - \\tfrac{1}{2\\theta} + \\tfrac{1}{2(\\ln(1-\\theta))^2} \\right)$"
  ),
  `Finitized pdf $f_2(x)$` = c(
    "$f_2(0)=1-\\lambda+\\tfrac{\\lambda^2}{2}$<br>$f_2(1)=\\lambda(1-\\lambda)$<br>$f_2(2)=\\tfrac{\\lambda^2}{2}$",
    "$f_2(0)=\\tfrac{1-4q+6q^2}{(1-q)^2}$<br>$f_2(1)=\\tfrac{2q(4q-1)}{(1-q)^2}$<br>$f_2(2)=\\tfrac{3q^2}{(1-q)^2}$",
    "$f_2(0)=1-4p+6p^2$<br>$f_2(1)=4p(1-3p)$<br>$f_2(2)=6p^2$",
    "$f_2(0)=\\tfrac{4-5\\theta+6\\theta^2}{2\\theta \\ln(1-\\theta)}$<br>$f_2(1)=\\tfrac{4\\theta-3\\theta^2}{2\\theta \\ln(1-\\theta)}$<br>$f_2(2)=\\tfrac{2-3\\theta+2\\theta^2}{2\\theta \\ln(1-\\theta)}$"
  ),
  `Parameter restriction` = c(
    "$0 < \\lambda \\leq 1$",
    "$0 < q \\leq 1/4$",
    "$0 < p \\leq 1/3$",
    "$0 < \\theta \\leq 0.440423$"
  ),
    stringsAsFactors = FALSE,
  check.names = FALSE   # <- keeps your LaTeX column names
)

kable(tab2, format = "markdown", align = "l", caption = "Table 2. Common PSDs and their finitized pdfs of order 2 using the NTFS method")
```

## Maximum Feasible Parameter Space (MFPS)

When constructing finitized distributions, not every parameter value from the parent distribution leads to a valid probability distribution. For a finitization of order \(n\), the probabilities must remain nonnegative and sum to one. This naturally restricts the parameter space of the parent power series distribution (PSD). The largest subset of the parameter space that yields a valid finitized distribution is called the *Maximum Feasible Parameter Space* (MFPS) [@golnabi2009finitizing; @levy2012moment; @levy2019application].

### Why MFPS is Necessary

Without enforcing MFPS constraints, the finitized pmf may assign negative probabilities, violating the axioms of probability. For example, while the classical Poisson distribution admits any \(\lambda > 0\), its finitized counterpart only produces a valid pmf when \(0 < \lambda \leq 1\), regardless of the finitization order [@golnabi2009finitizing]. For other PSDs, the admissible range is more complex and depends explicitly on the finitization order \(n\).

### How to Compute MFPS

Formally, the MFPS of a finitized distribution of order \(n\) is the largest interval \((\theta_{\min}, \theta_{\max}]\) such that all finitized probabilities are nonnegative and sum to one [@levy2019application].

- The **upper bound** \(\theta_{\max}\) is obtained by solving  
  \[
  g_n(n-1 \mid \theta) = 0,
  \]  
  where \(g_n\) is the finitized pmf. The largest positive root gives the admissible upper bound.  

- The **lower bound** \(\theta_{\min}\) is determined by examining when finitized probabilities near the lower edge of the support first reach zero. In many PSDs (Poisson, Binomial, Negative Binomial) this bound is simply 0, since probabilities remain valid for arbitrarily small positive parameters. For the logarithmic distribution, however, the lower bound can be strictly positive and depends on the finitization order (see [@levy2019application] for proofs and demonstrations).

### Properties of MFPS

- **Feasibility guarantee:** MFPS ensures that the finitized distribution is a proper pdf (all probabilities are nonnegative, summing to 1).
- **Order dependence:** For distributions such as the negative binomial or logarithmic, the MFPS upper bound decreases as the finitization order \(n\) increases.
- **Monotonicity:** For most PSDs, the MFPS shrinks as \(n\) increases. The exception is the Poisson distribution, whose MFPS remains constant across all orders.
- **Stability for Poisson:** The Poisson case is simple and stable, since the MFPS remains fixed at \([0,1]\).
- **Impact on modeling:** When selecting finitization order \(n\), one must ensure that the parameter values of interest lie within the MFPS.

### Example: Poisson and Logarithmic Distributions

- **Poisson:** For all orders \(n\), the MFPS is \(\lambda \in (0,1]\). This restriction is often natural in applications: if the mean count exceeds 1, one can rescale to a smaller time unit (e.g., accidents per day instead of accidents per week) to satisfy the condition [@golnabi2009finitizing].  
- **Logarithmic:** The MFPS depends on the finitization order. For instance, with order \(n=4\), the admissible range for \(\theta\) is approximately \((0.00012,\,0.2397)\), with the upper bound decreasing as \(n\) increases [@levy2019application].

---

In summary, MFPS is a central concept in finitization: it specifies the parameter values for which finitized distributions are mathematically valid. For rigorous proofs, derivations, and additional examples across the PSD family, the reader is referred to [@golnabi2009finitizing], [@levy2012moment], and [@levy2019application].


# Installing the `finitization` Package

The `finitization` package is available on CRAN and can be installed with a single command:

```{r, eval=FALSE}
install.packages("finitization")
```

After installation, the package can be loaded as usual:

```{r, message=FALSE}
library(finitization)
```

---

## External Dependencies

The package relies on three external C++ libraries:

- **CLN (Class Library for Numbers):** <https://www.ginac.de/CLN/>  
- **GiNaC (GiNaC is Not a CAS):** <https://www.ginac.de/>  
- **GMP (GNU Multiple Precision Arithmetic Library):** <https://gmplib.org/>  

These libraries are required because finitization involves symbolic series expansions and
moment-preserving transformations that need **arbitrary-precision arithmetic** (CLN, GMP) and
**symbolic computation** (GiNaC). Without them, the numerical accuracy and algebraic
manipulations required by finitization would not be feasible.

---

## Platform Notes

### Linux (Debian/Ubuntu)

Install the required libraries from the system package manager:

```{bash, eval=FALSE}
sudo apt-get update
sudo apt-get install -y libgmp-dev libcln-dev libginac-dev pkg-config
```

### macOS (Homebrew)

```{bash, eval=FALSE}
brew install gmp cln ginac pkg-config
```

### Windows

When building from source with **RTools** and **MSYS2**, CLN and GiNaC must be compiled manually from their official websites. 
1. **Install RTools44**  
   Download and run the installer from  
   https://cran.r-project.org/bin/windows/Rtools/

2. **Open the “MSYS2 UCRT 64‑bit” shell** 
   Supposing that RTools44 is installed in "C:/rtools44" then double click on "C:/rtools44/ucrt64.exe". 
   
3. **Fully update MSYS2, update the package database and install the toolchain + pkgconf**  
```bash
    pacman -Syu        # if it asks to close/reopen, do it, then run again:
    pacman -Syu
    pacman -S --needed mingw-w64-ucrt-x86_64-toolchain mingw-w64-ucrt-x86_64-pkgconf
```

4. **Install GMP**  
```bash
   pacman -S --needed mingw-w64-ucrt-x86_64-gmp
```

5. **Download, compile and install CLN and GiNaC**  
   CLN and GiNaC are not available via pacman; follow the instructions on their websites:  
   - **CLN (Class Library for Numbers):** https://www.ginac.de/cln  
   - **GiNaC (GiNaC is Not a CAS):** https://www.ginac.de  

   Example (adjust versions as needed):  
```bash
   # CLN
   pacman -S --needed wget
   wget https://www.ginac.de/CLN/cln-1.3.7.tar.bz2
   tar xf cln-1.3.7.tar.bz2
   cd cln-1.3.7
   ./configure --prefix=/ucrt64
   make
   make install
   cd ..

   # GiNaC
   wget https://www.ginac.de/ginac-1.8.9.tar.bz2
   tar xf ginac-1.8.9.tar.bz2
   cd ginac-1.8.9
   ./configure --prefix=/ucrt64
   make
   make install
 ```

6. **Make sure R sees the compilers**  
   In your R session (or add to your `~/.Renviron`):
```{r, eval=FALSE}
   Sys.setenv(PATH = paste(
     "C:/rtools44/ucrt64/bin",
     Sys.getenv("PATH"),
     sep = ";"
   ))
```

---

## Building from Source

To build from the GitHub development version:

```{bash, eval=FALSE}
git clone https://github.com/bogdanoancea/finitization.git
cd finitization
R CMD build .
R CMD INSTALL finitization_0.1.0.tar.gz
```

Or install directly from R using **devtools**:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("bogdanoancea/finitization")
```

## Hints for Successful Installation

- The **pkg-config** utility must be present and available to the compiler.
- Header files and libraries for CLN and GiNaC (e.g., under `/usr/include`, `/usr/lib`, or `/ucrt64/include`, `/ucrt64/lib`) must be accessible on the compiler’s search path.
- On Windows, potential errors such as “missing header” or “unresolved symbol” typically indicate that the build process is not detecting the static libraries.
- In general, manual configuration is required only on Windows, since macOS and Linux distributions handle dependencies through system package managers.

---

In summary, CRAN installation should work out of the box on all platforms. Manual configuration
is required only when compiling from source on Linux or when building custom versions of CLN and
GiNaC on Windows.

# Finitized Negative Binomial distribution

This section illustrates the finitization of the negative binomial (NB) distribution and
its implementation in the `finitization` package. The finitized NB restricts the support of
the classical NB distribution to \(\{0,1,\dots,n\}\) while preserving the first \(n\) moments
of the parent distribution [@levy2012moment; @kirtland2018application]. This construction is
particularly relevant in applied contexts where unbounded support is unrealistic, such as in
epidemiological models of infection counts, bounded population studies, or simulation
experiments requiring efficient random variate generation [@golnabi2009finitizing].

The finitized NB distribution is parameterized by three values:  
- **finitization order** \(n\), which determines the finite support \(\{0,\dots,n\}\);  
- **success probability** \(q\) per trial;  
- **number of failures until stopping** \(k > 0\).  

The subsections below present the main functions provided in the package together with
executable examples.

```{r}
library(finitization)

# Parameters used in the examples
n <- 5      # finitization order -> support {0, 1, ..., 5}
q <- 0.10   # success probability per trial (must lie within MFPS)
k <- 2      # number of failures until stopping
x <- 0:n
```

## PMF — `dnegbinom()`


The function `dnegbinom()` returns the probability mass function (PMF) of the finitized
negative binomial distribution. When the argument `val` is set to `NULL`, the function
produces the complete PMF over the finite support \(\{0,1,\dots,n\}\). Alternatively,
specific probability values can be obtained by supplying a vector of evaluation points
through `val`. For numerical stability and applications requiring likelihood calculations,
logarithmic probabilities can be returned by specifying `log = TRUE`.


```{r}
# Full PMF table over 0:n
pmf_tbl <- dnegbinom(n, q, k)       # val = NULL -> full table
head(pmf_tbl)

# PMF at selected points
d_points <- dnegbinom(n, q, k, val = c(0, 3, 5))
d_points

# Log-PMF for numerical work
d_log <- dnegbinom(n, q, k, val = 0:3, log = TRUE)
d_log
```


## CDF — `pnegbinom()`

The function `pnegbinom()` evaluates the cumulative distribution function (CDF) of the
finitized negative binomial distribution. By default, it returns lower-tail probabilities
\(\Pr(X \leq x)\) for values in \(\{0,1,\dots,n\}\). Setting `lower.tail = FALSE`
instead yields upper-tail probabilities \(\Pr(X > x)\), while the option `log.p = TRUE`
returns logarithmic probabilities, which may be advantageous in cases of very small tail
probabilities.

```{r}
# Full CDF table over 0:n
cdf_tbl <- pnegbinom(n, q, k)
head(cdf_tbl)

# Lower-tail CDF at a few points
p_lo <- pnegbinom(n, q, k, val = c(2, 3, 5))
p_lo

# Upper-tail probabilities (P[X > x])
p_hi <- pnegbinom(n, q, k, val = c(2, 3, 5), lower.tail = FALSE)
p_hi
```

## Quantiles — `qnegbinom()`

The function `qnegbinom()` provides the quantile function (inverse CDF) of the finitized
negative binomial distribution. Given a probability level \(p\), it returns the smallest
integer \(x \in \{0,\dots,n\}\) such that \(\Pr(X \leq x) \geq p\). The arguments
`lower.tail` and `log.p` control whether probabilities are interpreted in the lower- or
upper-tail sense and whether they are supplied on the log scale, respectively. This
function is particularly useful for simulation studies, where random draws may be generated
via inversion.

```{r}
# Median and 90th percentile
q_med_90 <- qnegbinom(n, q, k, p = c(0.5, 0.9))
q_med_90

# Upper-tail quantile example
q_upper10 <- qnegbinom(n, q, k, p = 0.1, lower.tail = FALSE)
q_upper10
```

## Random variates generation — `rnegbinom()`

The function `rnegbinom()` generates random variates from the finitized negative binomial
distribution on the finite support \(\{0,1,\dots,n\}\). The argument `no` specifies the
number of independent draws to produce. This functionality is essential for Monte Carlo
experiments and simulation studies, where one may wish to examine the finite-sample
properties of estimators or to benchmark statistical procedures under finitized models.


```{r}
set.seed(42)
no  <- 5e4
r   <- rnegbinom(n, q, k, no)

# Compare empirical frequencies with the theoretical PMF
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[0:5, ]
```

```{r}
# Quick visual check
plot(x, pmf_tbl$prob, type = "h", lwd = 2, xlab = "x", ylab = "Probability",
     main = "Finitized NB: PMF vs empirical frequencies")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n", legend = c("PMF", "Empirical"), pch = c(NA, 16), lty = c(1, NA))
```

## Maximum Feasible Parameter Space — `getNegativeBinomialMFPS()`

The function `getNegativeBinomialMFPS()` determines the boundaries of the maximum feasible
parameter space (MFPS) for the finitized negative binomial distribution. The MFPS specifies
the admissible range of parameter values (in particular for \(k\)) that guarantee the
resulting probability mass function remains nonnegative and normalized to one. Ensuring that
the chosen parameters lie within the MFPS is therefore essential for obtaining a valid
probability distribution under finitization.

```{r}
mfps <- getNegativeBinomialMFPS(n, k)
length(mfps); head(mfps)
```

## Closed-form display — `printFinitizedNegativeBinomialDensity()`

The function `printFinitizedNegativeBinomialDensity()` prints the finitized negative
binomial density in a symbolic, human-readable form. Optionally, evaluation points may be
supplied through the argument `val`, and setting `latex = TRUE` produces an expression
suitable for inclusion in LaTeX documents. This functionality facilitates the communication
of finitization results in teaching materials, presentations, and publications.

```{r}
printFinitizedNegativeBinomialDensity(n, k)
printFinitizedNegativeBinomialDensity(n, k, val = c(0, 1, 2))
printFinitizedNegativeBinomialDensity(n, k, latex = TRUE)
```

---

## Validation and Diagnostics

To ensure the correctness of the finitized negative binomial implementation, it is useful
to carry out a series of diagnostic checks. These include verification of the normalization
of the probability mass function (PMF), consistency between the cumulative distribution
function (CDF) and the cumulative sum of the PMF, monotonicity of the CDF, the accuracy of
the quantile function through inversion tests, and finally, agreement between theoretical
moments derived from the PMF and empirical moments obtained from simulated random draws.
The following code illustrates these diagnostic procedures in practice providing  
evidence that the finitized NB functions operate reliably and preserve
theoretical properties.

```{r}
# PMF/CDF from the finitized NB
pmf <- dnegbinom(n, q, k)                 
cdf <- pnegbinom(n, q, k)

# 1) Normalization of PMF
norm_err <- abs(sum(pmf$density) - 1)
norm_err

# 2) CDF consistency
cdf_from_pmf <- cumsum(pmf$density)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf$cdf))
cdf_diff_max

# 3) Monotonicity of the CDF
is_monotone <- all(diff(cdf$cdf) >= -1e-12)
is_monotone

# 4) Quantile inversion check
p_vec <- c(0.01, 0.10, 0.25, 0.5, 0.9, 0.99)
q_inv <- qnegbinom(n, q, k, p = p_vec)
check_q_ok <- mapply(function(p, qx) {
  lhs <- cdf$cdf[qx + 1L]                  
  rhs <- if (qx > 0) cdf$cdf[qx] else 0    
  (lhs + 1e-12 >= p) && (rhs + 1e-12 < p)
}, p_vec, q_inv)
cbind(p = p_vec, q = q_inv, ok = check_q_ok)

# 5) Simulation vs. PMF moments
set.seed(123)
no <- 1e5
r  <- rnegbinom(n, q, k, no)

mu_th  <- sum(x * pmf$prob)
var_th <- sum((x - mu_th)^2 * pmf$prob)

mu_emp  <- mean(r)
var_emp <- var(r)

cbind(theoretical = c(mean = mu_th, var = var_th),
      empirical    = c(mean = mu_emp, var = var_emp))

```
## Moment preservation for the finitized Negative Binomial

In the following, we compare the first `n` moments of the finitized negative binomial
distribution with those of its parent distribution. The classical negative binomial distribution
is obtained using the `stats` package in R. Since the `finitization` package and the `stats`
implementation adopt different parameterizations, a conversion is required to ensure comparability.

In the finitization framework, the parameter `q` represents the probability of success per trial,
and `k` denotes the number of failures until stopping. In contrast, in `stats::dnbinom`, the
parameterization is defined in terms of the number of successes (`size = k`) and the success
probability (`prob`). To reconcile the two conventions, the mapping

\[
\texttt{size} = k, \quad \texttt{prob} = 1 - q
\]

must be applied.

This alignment of parameter definitions allows for a consistent evaluation of the
moment-preserving property of finitization, as illustrated in the accompanying code.


```{r}
library(finitization)

# Parameters
n <- 5              # finitization order -> claims: first n moments preserved
q <- 0.10           # success probability per trial (package convention)
k <- 2              # number of failures until stopping (package convention)
x <- 0:n            # finite support of the finitized NB

# Parent NB in 'stats' uses: size = k (successes), prob = 1 - q (success probability)
size_parent <- k
prob_parent <- 1 - q
```

Next, we compute the finitized `pmf` as a numeric vector of length `n+1`
```{r}
pmf_raw <- dnegbinom(n, q, k) 
pmf_vec <- pmf_raw$prob
stopifnot(length(pmf_vec) == length(x))
stopifnot(abs(sum(pmf_vec) - 1) < 1e-10)
```

Now we compute the parent Negative Binomial `pmf` on a sufficiently long grid (for accurate moments).
For this we build a grid `{0, ... ,M}` so that the upper tail is negligible (here \(<10^{-14}\)).

```{r}
# Find M so that tail <= 1e-14
M <- 50L
repeat {
  tail <- 1 - stats::pnbinom(M, size = size_parent, prob = prob_parent)
  if (tail < 1e-14) break
  M <- M * 2L
  if (M > 1e6) stop("Grid grew too large while bounding the tail.")
}
grid <- 0:M
p_parent <- stats::dnbinom(grid, size = size_parent, prob = prob_parent)
stopifnot(abs(sum(p_parent) - 1) < 1e-10)
```
Now we can compute and compare the first `n` raw moments for both distributions:
```{r}
# Helper: raw moments from a discrete pmf
raw_moment <- function(x, p, r) sum((x^r) * p)

# Finitized moments on 0:n
mom_fin <- sapply(1:n, function(r) raw_moment(x, pmf_vec, r))

# Parent moments on 0:M (practically exact with very small tail)
mom_par <- sapply(1:n, function(r) raw_moment(grid, p_parent, r))

mom_cmp <- data.frame(
  r = 1:n,
  finitized = mom_fin,
  parent    = mom_par,
  diff      = mom_fin - mom_par
)
mom_cmp
```

We also present the mean and variance—the first two raw moments—explicitly. Closed-form
expressions are available for the parent negative binomial distribution, and these provide a
useful benchmark against which the finitized moments can be validated. In particular, for
parameters \(k\) (number of failures until stopping) and \(q\) (success probability per trial),
the parent distribution satisfies

\[
\mathbb{E}[X] = \frac{kq}{1-q}, \qquad
\mathrm{Var}(X) = \frac{kq}{(1-q)^2}.
\]

These closed-form expressions offer an efficient reference point for validation: they allow
one to verify the accuracy of finitized moments without resorting to numerical summation
over the entire distributional support. This comparison highlights the moment-preserving
property of finitization while emphasizing its consistency with the theoretical parent model.

```{r}
# Mean and variance separately (these are moments 1 and 2)
mean_fin <- mom_fin[1]
var_fin  <- raw_moment(x, pmf_vec, 2) - mean_fin^2

# Parent mean/var using both summation and closed forms for cross-check
mean_par_sum <- mom_par[1]
var_par_sum  <- (raw_moment(grid, p_parent, 2) - mean_par_sum^2)

# Closed-form moments for stats::NB(size=k, prob=1-q):
# E[X] = k*q/(1-q), Var[X] = k*q/(1-q)^2
mean_par_cf <- k * q / (1 - q)
var_par_cf  <- k * q / (1 - q)^2

data.frame(
  quantity  = c("mean", "variance"),
  finitized = c(mean_fin, var_fin),
  parent_sum= c(mean_par_sum, var_par_sum),
  parent_cf = c(mean_par_cf, var_par_cf),
  diff_fin_parent_cf = c(mean_fin - mean_par_cf, var_fin - var_par_cf)
)
```



# Finitized Binomial Distribution

The classical binomial distribution models the number of successes in \(N\) independent
Bernoulli trials, each with success probability \(p\). Its support is finite,
\(\{0,1,\dots,N\}\). Finitization provides an alternative construction: a finitized
binomial distribution of order \(n\) that preserves the first \(n\) moments of the
parent binomial distribution while adjusting the probability mass function through the
moment-preserving finitization series (MFPS) [@levy2012moment]. This construction
ensures that the finitized model remains consistent with the theoretical binomial
moments up to order \(n\), even though its support is restricted to \(\{0,1,\dots,n\}\).

The finitized binomial distribution in the `finitization` package is parameterized by:
- **finitization order** \(n\), which sets the support \(\{0,\dots,n\}\);  
- **success probability** \(p\);  
- **number of trials** \(N\).  

The subsections below present the available functions and illustrate their use.

```{r}
library(finitization)

# Parameters for the examples
n <- 5      # finitization order -> support {0, 1, ..., 5}
N <- 10     # number of Bernoulli trials in the parent distribution
p <- 0.14    # success probability
x <- 0:n
```


## PMF — `dbinom()`
The probability mass function (PMF) of the finitized binomial distribution is computed by
dbinom(). When `val = NULL`, the function returns the entire PMF over
({0,\dots,n}). Specific probabilities can be extracted by supplying values in `val`.
For likelihood calculations and improved numerical stability, log-probabilities are
returned with the argument `log = TRUE`.

```{r}
# Full PMF over 0:n
pmf_tbl <- finitization::dbinom(n, p, N)
head(pmf_tbl)

# PMF at selected points
d_points <- finitization::dbinom(n, p, N, val = c(0, 2, 5))
d_points

# Log-PMF for selected values
d_log <- finitization::dbinom(n, p, N, val = 0:3, log = TRUE)
d_log
```

## CDF — `pbinom()`

The cumulative distribution function (CDF) is available via `pbinom()`. By default, it
returns lower-tail probabilities \( \Pr(X \le x) \). Setting `lower.tail = FALSE` gives
upper-tail probabilities \( \Pr(X > x) \). The option `log.p = TRUE` returns values on the
logarithmic scale.

```{r}
# Full CDF table over 0:n
cdf_tbl <- finitization::pbinom(n, p, N)
head(cdf_tbl)

# Lower-tail probabilities at selected points
p_lo <- finitization::pbinom(n, p, N, val = c(2, 4, 5))
p_lo

# Upper-tail probabilities
p_hi <- finitization::pbinom(n, p, N, val = c(2, 4, 5), lower.tail = FALSE)
p_hi
```

## Quantiles — `qbinom()`

The function `qbinom()` computes quantiles of the finitized binomial distribution by
inverting the CDF. Given probability levels (`u`), it returns the smallest integer
\(x \in {0,\dots,n}\) such that \(\Pr(X \le x) \ge u\). The arguments `lower.tail`
and `log.p` allow specification of upper-tail and log-scale probabilities.

```{r}
# Median and 90th percentile
q_med_90 <- finitization::qbinom(n, p, N, prob = c(0.5, 0.9))
q_med_90

# Upper-tail quantile
q_upper10 <- finitization::qbinom(n, p, N, prob = 0.1, lower.tail = FALSE)
q_upper10
```


## Random Variates Generation — `rbinom()`

Random variates from the finitized binomial distribution are generated using `rbinom()`.
The argument no specifies the number of independent draws. This functionality is
useful for simulation studies, where empirical properties can be compared with theoretical
moments.

```{r}
set.seed(123)
no <- 5e4
r <- finitization::rbinom(n, p, N, no)

# Compare empirical frequencies with the theoretical PMF
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[1:6, ]

# Visual comparison of theoretical and empirical frequencies
plot(x, pmf_tbl$prob, type = "h", lwd = 2,
     main = "Finitized Binomial: PMF vs empirical frequencies",
     xlab = "x", ylab = "Probability")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n",
       legend = c("PMF", "Empirical"),
       pch = c(NA, 16), lty = c(1, NA))

```

## Maximum Feasible Parameter Space — `getBinomialMFPS()`

The function `getBinomialMFPS()` determines the maximum feasible parameter space (MFPS)
for the finitized binomial distribution. The MFPS specifies the admissible range of
parameters that guarantee the distribution is valid (nonnegative probabilities and total
probability equal to one).

```{r}
mfps <- finitization::getBinomialMFPS(n, N)
mfps
```

## Closed-form display — `printFinitizedBinomialDensity()`

The density of the finitized binomial distribution can be displayed symbolically with
`printFinitizedBinomialDensity()`. This allows for inspection of the closed-form
representation of the probability function. The option `latex = TRUE` produces output
suitable for inclusion in LaTeX documents.

```{r}
printFinitizedBinomialDensity(n, N)
printFinitizedBinomialDensity(n, N, val = c(0, 1, 2))
printFinitizedBinomialDensity(n, N, latex = TRUE)
```

## Validation and Diagnostics

Validation confirms that the finitized binomial functions operate correctly. Checks
include:normalization of the PMF, consistency between CDF and PMF, monotonicity 
of the CDF, quantile inversion accuracy, agreement between theoretical 
and empirical moments.
```{r}
pmf <- finitization::dbinom(n, p, N)
cdf <- finitization::pbinom(n, p, N)

# 1) Normalization
norm_err <- abs(sum(pmf$prob) - 1)

# 2) CDF consistency
cdf_from_pmf <- cumsum(pmf$prob)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf$cdf))

# 3) Monotonicity
is_monotone <- all(diff(cdf$cdf) >= -1e-12)

# 4) Quantile inversion check
p_vec <- c(0.1, 0.25, 0.5, 0.9)
q_inv <- finitization::qbinom(n, p, N, prob = p_vec)
check_q_ok <- mapply(function(u, qx) {
  lhs <- cdf$cdf[qx + 1L]
  rhs <- if (qx > 0) cdf$cdf[qx] else 0
  (lhs + 1e-12 >= u) && (rhs + 1e-12 < u)
}, p_vec, q_inv)

# 5) Simulation vs. PMF moments
set.seed(456)
r_samp <- finitization::rbinom(n, p, N, 1e5)
mu_emp <- mean(r_samp)
var_emp <- var(r_samp)

mu_th <- sum(x * pmf$prob)
var_th <- sum((x - mu_th)^2 * pmf$prob)

list(norm_err = norm_err,
     cdf_diff_max = cdf_diff_max,
     monotone = is_monotone,
     quantile_check = check_q_ok,
     mean_theoretical = mu_th, mean_empirical = mu_emp,
     var_theoretical = var_th, var_empirical = var_emp)
```

# Finitized Poisson Distribution

This section follows the structure introduced for the finitized **Negative Binomial** and **Binomial** distributions, but in a more concise form. The finitized Poisson of order \(n\) replaces the infinite-support Poisson by a distribution supported on \(\{0,1,...,n\}\) that preserves the first \(n\) moments of the parent model.


```{r}
library(finitization)

# Parameters used in the examples
n     <- 5      # finitization order -> support {0, 1, ..., 5}
theta <- 0.7    # Poisson mean (ensure theta lies within the MFPS for this n)
x     <- 0:n
```
## PMF — `dpois()`
Returns the finitized Poisson probability mass function (PMF). With `val = NULL`, the full PMF over ({0,...,n}) is provided; logarithms are available via `log = TRUE`.
```{r}
# Full PMF table over 0:n
pmf_tbl <- finitization::dpois(n, theta)
head(pmf_tbl)

# PMF at selected points
d_points <- finitization::dpois(n, theta, val = c(0, 2, 5))
d_points

# Log-PMF for numerical work
d_log <- finitization::dpois(n, theta, val = 0:3, log = TRUE)
d_log
```

## CDF — `ppois()`

Evaluates the finitized Poisson CDF. Lower tail \(\Pr(X \le x)\) is returned by default; set `lower.tail = FALSE` for \(\Pr(X > x)\), and `log.p = TRUE` for log-CDF.

```{r}
# Full CDF table
cdf_tbl <- ppois(n, theta)
head(cdf_tbl)

# Selected points (lower and upper tails)
p_lo <- ppois(n, theta, val = c(1, 3, 5))
p_hi <- ppois(n, theta, val = c(1, 3, 5), lower.tail = FALSE)
p_lo; p_hi
```

## Quantiles — `qpois()`
Inverts the finitized CDF. For a probability vector p, returns the smallest \(x \in {0,\dots,n}\) with \(\Pr(X \le x) \ge p\).

```{r}
# Median and 90th percentile
q_med_90 <- qpois(n, theta, p = c(0.5, 0.9))
q_med_90

# Upper-tail quantile example
q_upper10 <- qpois(n, theta, p = 0.1, lower.tail = FALSE)
q_upper10
```

## Random Variates Generation — `rpois()`
```{r}
set.seed(2025)
no <- 5e4
r  <- rpois(n, theta, no)

# Empirical vs. theoretical frequencies (first rows)
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[1:6, ]
# Quick visual check
plot(x, pmf_tbl$prob, type = "h", lwd = 2,
     main = "Finitized Poisson: PMF vs empirical frequencies",
     xlab = "x", ylab = "Probability")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n",
       legend = c("PMF", "Empirical"),
       pch = c(NA, 16), lty = c(1, NA))
```

## Maximum Feasible Parameter Space — `getPoissonMFPS()`
Returns the MFPS for \(\\theta\) given \(n\); choosing \(\\theta\) within these bounds ensures a valid (nonnegative, normalized) finitized PMF.
```{r}
getPoissonMFPS(n)
```

## Closed-form — `printFinitizedPoissonDensity()`
Prints a symbolic representation of the finitized Poisson PMF; `latex = TRUE` produces LaTeX-ready output.
```{r}
printFinitizedPoissonDensity(n)
printFinitizedPoissonDensity(n, val = c(0, 1, 2))
printFinitizedPoissonDensity(n, latex = TRUE)
```

## Validation and Disgnostics

The following diagnostics assess the internal consistency of the finitized Poisson implementation:
(i) normalization of the PMF; (ii) agreement between the CDF and cumulative PMF; (iii) CDF monotonicity;
(iv) quantile inversion accuracy; (v) **moment preservation** (first `n` raw moments) relative to the classical Poisson; and (vi) simulation consistency.

```{r}
# Assumes 'n', 'theta', and x <- 0:n are already defined (see the Poisson section header).
# If not, uncomment the next three lines:
# n     <- 5
# theta <- 0.7
# x     <- 0:n

# --- 1) Finitized PMF/CDF ---
pmf_fin <- dpois(n, theta)    # data.frame: columns 'val', 'prob' (or log-prob if log=TRUE)
cdf_fin <- ppois(n, theta)    # data.frame: columns 'val', 'cdf'  (or log-cdf if log.p=TRUE)

# Normalization (PMF sums to 1 up to rounding)
norm_err <- abs(sum(pmf_fin$prob) - 1)

# CDF = cumulative sum of PMF (within numerical tolerance)
cdf_from_pmf <- cumsum(pmf_fin$prob)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf_fin$cdf))

# CDF monotonicity
is_monotone <- all(diff(cdf_fin$cdf) >= -1e-12)

list(
  normalization_error = norm_err,
  cdf_max_abs_diff    = cdf_diff_max,
  cdf_monotone        = is_monotone
)

# --- 2) Quantile inversion accuracy ---
# For each p, q := qpois(n, theta, p) should satisfy: F(q) >= p and F(q-1) < p
p_vec <- c(0.01, 0.10, 0.25, 0.5, 0.9, 0.99)
q_inv <- qpois(n, theta, p = p_vec)

# Helper to get F(x) from the finitized CDF table (values start at 0, so index = x+1)
Ffin <- function(qx) if (qx < 0) 0 else cdf_fin$cdf[qx + 1L]

qinversion_ok <- mapply(function(p, qx) {
  (Ffin(qx) + 1e-12 >= p) && (Ffin(qx - 1L) + 1e-12 < p)
}, p_vec, q_inv)

data.frame(p = p_vec, q = q_inv, inversion_ok = qinversion_ok)

# --- 3) Moment preservation vs. classical Poisson ---
# We compare the first n raw moments of the finitized Poisson to the parent Poisson($\\theta$).
# Parent moments are computed by summation over {0,...,M} with negligible tail (< 1e-14).

# Finitized raw moments on {0..n}
raw_moment <- function(xx, pp, r) sum((xx^r) * pp)
mom_fin <- sapply(1:n, function(r) raw_moment(x, pmf_fin$prob, r))

# Choose M so that tail <= 1e-14 for the classical Poisson
M <- max(50L, ceiling(theta + 10*sqrt(theta))) # start with a reasonable guess
repeat {
  tail <- 1 - stats::ppois(M, lambda = theta)  # NOTE: explicit 'stats::' to avoid masking
  if (tail < 1e-14) break
  M <- M * 2L
  if (M > 1e6) stop("Grid grew too large while bounding the tail.")
}
grid <- 0:M
p_parent <- stats::dpois(grid, lambda = theta)  # classical Poisson PMF on {0..M}

# Parent raw moments (virtually exact with tiny tail)
mom_par <- sapply(1:n, function(r) raw_moment(grid, p_parent, r))

mom_cmp <- data.frame(
  r         = 1:n,
  finitized = mom_fin,
  parent    = mom_par,
  diff      = mom_fin - mom_par
)
mom_cmp

# --- 4) Simulation sanity check ---
# Samples from finitized Poisson should exhibit moments close to the finitized-theoretical ones.
set.seed(2025)
no <- 1e5
rs <- rpois(n, theta, no)

mean_emp <- mean(rs)
var_emp  <- var(rs)

mean_fin <- sum(x * pmf_fin$prob)
var_fin  <- sum( (x - mean_fin)^2 * pmf_fin$prob )

data.frame(
  quantity   = c("mean", "variance"),
  empirical  = c(mean_emp, var_emp),
  finitized  = c(mean_fin, var_fin),
  abs_diff   = c(abs(mean_emp - mean_fin), abs(var_emp - var_fin))
)
```

# Finitized Logarithmic distribution

This section follows the structure already introduced for the finitized **Negative Binomial**, **Binomial** and **Poisson** distributions, in a concise form. The finitized logarithmic (log‑series) 
distribution of order \(n\) replaces the classical infinite‑support model with 
a distribution supported on \(\{0,1,...,n\}\) while preserving the first \(n\) moments of its parent.


```{r}
library(finitization)

# Parameters used in the examples
n      <- 3      # finitization order -> support {0, 1, 2, 3}
theta  <- 0.16   # log-series parameter (0 < theta < 1); ensure within MFPS for 'n'
x      <- 0:n
```

---

## PMF — `dlog()`

Returns the finitized logarithmic PMF. With `val = NULL`, the full PMF over \(\{0,...,n\}\) is returned; set `log = TRUE` for log‑probabilities.

```{r}
# Full PMF table over 0:n
pmf_tbl <- finitization::dlog(n, theta)
head(pmf_tbl)

# PMF at selected points
d_points <- finitization::dlog(n, theta, val = c(0, 2, 3))
d_points

# Log-PMF for numerical work
d_log <- finitization::dlog(n, theta, val = 0:3, log = TRUE)
d_log
```

---

## CDF — `plog()`

Evaluates the finitized logarithmic CDF. Lower tail \(\Pr(X \le x)\) is returned by default; use `lower.tail = FALSE` for upper tails and `log.p = TRUE` for log‑CDF.

```{r}
# Full CDF table
cdf_tbl <- finitization::plog(n, theta)
head(cdf_tbl)

# Selected points (lower and upper tails)
p_lo <- finitization::plog(n, theta, val = c(1, 3))
p_hi <- finitization::plog(n, theta, val = c(1, 3), lower.tail = FALSE)
p_lo; p_hi
```

---

## Quantiles — `qlog()`

Inverts the finitized CDF. For a probability vector `p`, returns the smallest \(x \in \{0,...,n\}\) with \(\Pr(X \le x) \ge p\).

```{r}
# Median and 90th percentile
q_med_90 <- finitization::qlog(n, theta, p = c(0.5, 0.9))
q_med_90

# Upper-tail quantile example
q_upper10 <- finitization::qlog(n, theta, p = 0.1, lower.tail = FALSE)
q_upper10
```

---

## Random Variates Generation — `rlog()`

Generates samples from the finitized logarithmic distribution on \(\{0,...,n\}\).

```{r}
set.seed(2025)
no <- 5e6
r  <- finitization::rlog(n, theta, no)

# Empirical vs. theoretical frequencies (first rows)
freq <- table(factor(r, levels = x)) / no
cbind(x = x, pmf = pmf_tbl$prob, emp = as.numeric(freq))[1:4, ]
```

```{r}
# Quick visual check
plot(x, pmf_tbl$prob, type = "h", lwd = 2,
     main = "Finitized Logarithmic: PMF vs empirical frequencies",
     xlab = "x", ylab = "Probability")
points(x, as.numeric(freq), pch = 16)
legend("topright", bty = "n",
       legend = c("PMF", "Empirical"),
       pch = c(NA, 16), lty = c(1, NA))
```

---

## Maximum Feasible Parameter Space — `getLogarithmicMFPS()`

Returns the **MFPS** for `theta` given `n`; parameter choices within this interval ensure a valid finitized PMF (nonnegative and normalized).

```{r}
getLogarithmicMFPS(n)
```

---

## Closed-form dispay — `printFinitizedLogarithmicDensity()`

Prints a symbolic representation of the finitized logarithmic PMF; `latex = TRUE` yields LaTeX‑ready output.

```{r}
printFinitizedLogarithmicDensity(n, val = c(0))
```

---

## Moment Preservation (first \(n\) raw moments)

We compare the first \(n\) raw moments of the finitized logarithmic distribution with those of a
**zero-including log-series parent** whose moment generating function (MGF) is
\[
m_X(t) \;=\; \frac{\ln(1-\theta e^{t})}{e^{t}\,\ln(1-\theta)}, \qquad 0<\theta<1.
\]
This corresponds to a log-series shifted to include 0 in its support, with pmf
\[
\Pr(X=x) \;=\; -\frac{1}{\ln(1-\theta)}\,\frac{\theta^{x+1}}{x+1}, \quad x=0,1,2,\dots
\]
We verify that the finitized distribution (order \(n\), support \(\{0,\dots,n\}\)) preserves the
first \(n\) raw moments of this parent.



```{r}
# --- Finitized raw moments on {0..n} ---
pmf_fin_tbl <- finitization::dlog(n, theta)   # expected: data.frame with columns 'val', 'prob'
stopifnot(is.data.frame(pmf_fin_tbl), all(c("val","prob") %in% names(pmf_fin_tbl)))
stopifnot(all(pmf_fin_tbl$val == x))
stopifnot(abs(sum(pmf_fin_tbl$prob) - 1) < 1e-12)

pmf_fin <- pmf_fin_tbl$prob
head(pmf_fin_tbl)


```
We compute parent moments by summation on ({0,...,M}) with negligible tail (< (10^{-14})).
```{r}
# Parent pmf implied by the given MGF (zero-including log-series)
dlog_parent0 <- function(x, theta) {
  -1 / log(1 - theta) * theta^(x + 1) / (x + 1)
}

# Choose M until the remaining tail mass is < 1e-14
M <- 200L
repeat {
  s <- sum(dlog_parent0(0:M, theta))
  tail <- 1 - s
  if (tail < 1e-14) break
  M <- M * 2L
  if (M > 1e7) stop("Grid grew too large while bounding the tail.")
}
grid  <- 0:M
p_par <- dlog_parent0(grid, theta)
stopifnot(abs(sum(p_par) - 1) < 1e-10)

c(head(data.frame(x = grid, p = p_par), 6),
  tail_mass = 1 - sum(p_par))

raw_moment <- function(xx, pp, r) sum( (xx^r) * pp )

mom_fin <- sapply(1:n, function(r) raw_moment(x,    pmf_fin, r))
mom_par <- sapply(1:n, function(r) raw_moment(grid, p_par,    r))

mom_cmp <- data.frame(
  r         = 1:n,
  finitized = mom_fin,
  parent    = mom_par,
  diff      = mom_fin - mom_par
)
mom_cmp

```

---

## Validation and  Diagnostics

A compact set of checks, consistent with the other finitized families:

```{r}
pmf <- finitization::dlog(n, theta)
cdf <- finitization::plog(n, theta)

# Normalization
norm_err <- abs(sum(pmf$prob) - 1)

# CDF consistency and monotonicity
cdf_from_pmf <- cumsum(pmf$prob)
cdf_diff_max <- max(abs(cdf_from_pmf - cdf$cdf))
is_monotone  <- all(diff(cdf$cdf) >= -1e-12)

# Quantile inversion check
p_vec <- c(0.01, 0.1, 0.25, 0.5, 0.9, 0.99)
q_inv <- finitization::qlog(n, theta, p = p_vec)
Ffin  <- function(qx) if (qx < 0) 0 else cdf$cdf[qx + 1L]
qinversion_ok <- mapply(function(p, qx) {
  (Ffin(qx) + 1e-12 >= p) && (Ffin(qx - 1L) + 1e-12 < p)
}, p_vec, q_inv)

list(
  normalization_error = norm_err,
  cdf_max_abs_diff    = cdf_diff_max,
  cdf_monotone        = is_monotone,
  quantile_inversion  = qinversion_ok
)
```
# Applications of finitized distributions

## Random Number Generators: Alias Method implemented in `finitization` vs. Parent Distributions

The `r*` functions in **finitization** implement an **aliasing**-based generator to produce
random variates on the finite support \(\{0,\dots,n\}\) with very low constant-time cost per draw.
To illustrate relative performance, we compare the finitized generators against their
classical/parent generators from `stats` package and, for the logarithmic-series, from `extraDistr`
package. 

> **Note.**
>   Parameters are chosen to lie within the **MFPS** for the finitized models so that the
>    PMFs are valid (nonnegative and normalized).

```{r}
# ---- Timings for random variates  ----

# Workload
no      <- 1e6      # draws per generator call
batches <- 5L       # average over this many batches
target  <- 0.05     # >= 50 ms per batch for stable timing

# Optional parent for Logarithmic (extraDistr::rlgser)
have_extraDistr <- requireNamespace("extraDistr", quietly = TRUE)

# Auto-scale inner loop so each batch is long enough; return sec per one call
avg_time_per_call <- function(fun, b = batches, t = target) {
  reps <- 1L
  invisible(fun())  # warm-up
  repeat {
    t0 <- proc.time()[["elapsed"]]
    for (b in seq_len(b)) {
      for (r in seq_len(reps)) fun()
    }
    dt <- proc.time()[["elapsed"]] - t0
    if ((dt / b) >= t || reps >= 1e5L) {
      return((dt / b) / reps)
    }
    reps <- reps * 10L
  }
}

# Parameters
pars <- list(
  pois = list(n = 3L, theta = 0.10),
  nbin = list(n = 3L, q = 0.10, k = 5L),      # parent: size = k, prob = 1 - q
  bin  = list(n = 3L, p = 0.10, N = 10L),
  log  = list(n = 3L, theta = 0.10)           # parent via extraDistr::rlgser() - 1
)

# One-call closures (each call draws 'no' variates)
fun_fin_pois <- function() finitization::rpois(pars$pois$n, pars$pois$theta, no)
fun_par_pois <- function() stats::rpois(no, lambda = pars$pois$theta)

fun_fin_nbin <- function() finitization::rnegbinom(pars$nbin$n, pars$nbin$q, pars$nbin$k, no)
fun_par_nbin <- function() stats::rnbinom(no, size = pars$nbin$k, prob = 1 - pars$nbin$q)

fun_fin_bin  <- function() finitization::rbinom(pars$bin$n, pars$bin$p, pars$bin$N, no)
fun_par_bin  <- function() stats::rbinom(no, size = pars$bin$N, prob = pars$bin$p)

fun_fin_log  <- function() finitization::rlog(pars$log$n, pars$log$theta, no)
fun_par_log  <- if (have_extraDistr) function() extraDistr::rlgser(no, pars$log$theta) - 1L else NULL

# Measure (pass batches/target explicitly if you want)
t_fin_pois <- avg_time_per_call(fun_fin_pois, b = batches, t = target)
t_par_pois <- avg_time_per_call(fun_par_pois, b = batches, t = target)

t_fin_nbin <- avg_time_per_call(fun_fin_nbin, b = batches, t = target)
t_par_nbin <- avg_time_per_call(fun_par_nbin, b = batches, t = target)

t_fin_bin  <- avg_time_per_call(fun_fin_bin,  b = batches, t = target)
t_par_bin  <- avg_time_per_call(fun_par_bin,  b = batches, t = target)

t_fin_log  <- avg_time_per_call(fun_fin_log,  b = batches, t = target)
t_par_log  <- if (!is.null(fun_par_log)) avg_time_per_call(fun_par_log, b = batches, t = target) else NA_real_

# Speedup = parent / finitized (how many times faster finitized is)
res <- data.frame(
  Family  = c("Poisson", "NegBin", "Binomial", "Logarithmic"),
  Speedup = c(
    t_par_pois / t_fin_pois,
    t_par_nbin / t_fin_nbin,
    t_par_bin  / t_fin_bin,
    t_par_log  / t_fin_log
  ),
  check.names = FALSE
)

cat(
  sprintf("%-12s %s\n", "Family", "Speedup (finitized versus parent)"),
  paste(
    sprintf("%-12s %22.14f", res$Family, res$Speedup),
    collapse = "\n"
  ),
  sep = "\n"
)
```
# References
